{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"rev",
				"reverseWords\tfunction"
			],
			[
				"bina",
				"binarySearch"
			],
			[
				"ac",
				"ascii_uppercase\tstatement"
			],
			[
				"up",
				"ascii_uppercase\tstatement"
			],
			[
				"s",
				"shoppingOffers"
			],
			[
				"insert",
				"insert_improve"
			],
			[
				"sele",
				"selected_ids"
			],
			[
				"tex",
				"\\textit{}"
			],
			[
				"re",
				"residual\tfunction"
			],
			[
				"co",
				"coeffs"
			],
			[
				"th",
				"thresholds"
			],
			[
				"chek",
				"check_after\tparam"
			],
			[
				"C",
				"C_first\tstatement"
			],
			[
				"wa",
				"warminit"
			],
			[
				"based",
				"base_dir"
			],
			[
				"sel",
				"selected_ids"
			],
			[
				"war",
				"warminit\t(utils.py)"
			],
			[
				"cal",
				"calc_res_cy\t(mycython.pyx)"
			],
			[
				"zer",
				"zeros_like\tfunction"
			],
			[
				"text",
				"\\textit{}"
			],
			[
				"solv_b_sep_",
				"solve_b_uc_sepC_all_2way\tfunction"
			],
			[
				"ce",
				"cells\tstatement"
			],
			[
				"as",
				"asarray"
			],
			[
				"dou",
				"double_t"
			],
			[
				"keep",
				"keepdims"
			],
			[
				"te",
				"\\textit{}"
			],
			[
				"t",
				"\\textwidth"
			],
			[
				"in",
				"intersect"
			],
			[
				"q",
				"query"
			],
			[
				"batch",
				"batch_size"
			],
			[
				"bat",
				"batch_size"
			],
			[
				"fr",
				"from_numpy"
			],
			[
				"hfc",
				"h_fc1"
			],
			[
				"h",
				"h_pool1"
			],
			[
				"polar",
				"polars"
			],
			[
				"grounds",
				"ground_scale"
			],
			[
				"pola",
				"polars"
			],
			[
				"one_hot",
				"one_hot_train"
			],
			[
				"per",
				"permutation\t(utils.py)"
			],
			[
				"pred",
				"predict\t(README)"
			],
			[
				"arr",
				"arrangeCoins"
			],
			[
				"diam",
				"diameterOfBinaryTree"
			],
			[
				"reducm",
				"reduce_mean\tfunction"
			],
			[
				"sum",
				"reduce_sum\tfunction"
			],
			[
				"hid2",
				"hidden2_output"
			],
			[
				"hid1",
				"hidden1_output"
			],
			[
				"sigm",
				"sigmoid\tfunction"
			],
			[
				"hids",
				"hidden2_size"
			],
			[
				"hidd",
				"hidden2_size"
			],
			[
				"variables",
				"variables\tmodule"
			],
			[
				"sort",
				"sorted_ii"
			],
			[
				"fu",
				"future\t(Tensor_TAES.tex)"
			],
			[
				"sty",
				"style\t(Tensor_TAES.tex)"
			],
			[
				"ass",
				"assets\t(.gitignore)"
			],
			[
				"mat",
				"\\mathcal"
			],
			[
				"lambda",
				"lambdas"
			],
			[
				"lam",
				"lambdas"
			],
			[
				"opts",
				"opts_FDDL"
			],
			[
				"math",
				"\\mathbf"
			],
			[
				"result",
				"results"
			],
			[
				"solv",
				"solve_b_uc\tfunction"
			],
			[
				"rel",
				"rel2abs"
			],
			[
				"ss_re",
				"ss_rel2abs1"
			],
			[
				"calc",
				"calc_res"
			],
			[
				"Y_t",
				"Y_test"
			],
			[
				"Y_train",
				"Y_train_ground"
			],
			[
				"Right",
				"\\Rightleftarray"
			],
			[
				"SS",
				"SSCQ_utils\t(Notes.md)"
			],
			[
				"kee",
				"keepdims\tparam"
			],
			[
				"eval",
				"evaluate"
			],
			[
				"updaB",
				"updateB_1"
			],
			[
				"cel",
				"cell"
			],
			[
				"eps",
				"epsilon"
			],
			[
				"machinelearnin",
				"machinelearningcoban.com"
			],
			[
				"grad",
				"grad_fCm_cython"
			],
			[
				"train_dir_",
				"train_dir_30"
			],
			[
				"su",
				"sub_code\tfunction"
			],
			[
				"back",
				"background-color"
			],
			[
				"Inc",
				"IncrementAngle"
			],
			[
				"new",
				"n_views"
			],
			[
				"nu",
				"n_users"
			],
			[
				"help",
				"helper"
			],
			[
				"Lis",
				"ListNode"
			],
			[
				"normal",
				"normalized"
			],
			[
				"prin",
				"print_recommendation\tfunction"
			],
			[
				"random",
				"random_normal\tfunction"
			],
			[
				"flo",
				"float32\tstatement"
			],
			[
				"sess",
				"session=sess\t(SRCNN_ver8_Tiep.py)"
			],
			[
				"glo",
				"global_variables_initializer\t(logistic_regression.py)"
			],
			[
				"gre",
				"greater\tfunction"
			],
			[
				"reduce",
				"reduce_sum\t(logistic_regression.py)"
			],
			[
				"multi",
				"multiply\tfunction"
			],
			[
				"sub",
				"subtract\tfunction"
			],
			[
				"trip",
				"triplets"
			],
			[
				"relat",
				"relation_triplets"
			],
			[
				"test",
				"testdata"
			],
			[
				"sig",
				"sigma\tparam"
			],
			[
				"k",
				"keys\tfunction"
			],
			[
				"retri",
				"retrieved_num"
			],
			[
				"retrie",
				"retrieved_relevant_num"
			],
			[
				"y_te",
				"y_test"
			],
			[
				"ph",
				"phi\tfunction"
			],
			[
				"phi",
				"phiX\tstatement"
			],
			[
				"Ham",
				"Hamming_dist_naive"
			],
			[
				"compac",
				"compactbit_naive\tfunction"
			],
			[
				"bit",
				"bit2word"
			],
			[
				"int",
				"int8\timport"
			],
			[
				"a",
				"array"
			],
			[
				"repm",
				"repmat\tfunction"
			],
			[
				"optim",
				"optimize\tfunction"
			],
			[
				"My",
				"MyFista2\tclass"
			],
			[
				"shrin",
				"shrinkage\tfunction"
			],
			[
				"ini",
				"initialize"
			],
			[
				"pickD",
				"pickDfromY\tfunction"
			],
			[
				"thre",
				"threeSumClosest\tfunction"
			],
			[
				"myf",
				"myfunc"
			],
			[
				"best",
				"best_last2"
			],
			[
				"best_",
				"best_last1"
			],
			[
				"best_l",
				"best_last2"
			],
			[
				"D",
				"D_range"
			],
			[
				"accu",
				"accuracy_score\tfunction"
			],
			[
				"lass",
				"lasso_fista\tfunction"
			],
			[
				"optimiza",
				"optimization_problems\tmodule"
			],
			[
				"last",
				"lasso_fista_test"
			],
			[
				"gra",
				"grad_f\tstatement"
			],
			[
				"shri",
				"shrinkage_func"
			],
			[
				"check",
				"check_grad"
			],
			[
				"sh",
				"shrinkage_func"
			]
		]
	},
	"buffers":
	[
		{
			"contents": "% \\documentclass[xcolor=dvipsnames,10pt]{beamer}\n\\documentclass[10pt,xcolor=dvipsnames]{beamer}\n% \\usepackage{beamerthemebars}\n% \\usepackage[bars]{beamerthemetree}\n\\usepackage{multicol}\n\n\\usepackage{appendixnumberbeamer}\n\n\n% \\setbeamercovered{highly dynamic}\n\\input{mypackagebeamer}\n\\input{definitions}\n\n\\usepackage{tikz}\n\\usetheme{Dresden}\n% \\usetheme{default}\n%\\usecolortheme{lily}\n\\useoutertheme[subsection=false]{smoothbars}\n%\\useoutertheme[subsection=false]{miniframes}\n\\useinnertheme{circles}\n\\usefonttheme[onlymath]{serif}\n\\setbeamertemplate{navigation symbols}\n%\\setRL\n%\\insertslidenavigationsymbol\n\n\\setbeamertemplate{footline}[frame number]\n\n\n\\setbeamersize{text margin left=0.5cm,text margin right=0.5cm}\n% \\usetheme{Dresden}\n% %\\usecolortheme{lily}\n% \\useoutertheme[subsection=false]{smoothbars}\n% %\\useoutertheme[subsection=false]{miniframes}\n% \\useinnertheme{circles}\n% \\usefonttheme[onlymath]{serif}\n% \\setbeamertemplate{navigation symbols}\n%\\setRL\n%\\insertslidenavigationsymbol\n\n% \\setbeamertemplate{footline}[frame number]\n% \\usepackage{biblatex}\n% \\bibliography{ISBI_2015_revise_2}\n% \\newenvironment{changemargin}[2]{% \n%   \\begin{list}{}{% \n%     \\setlength{Tsep}{0pt}% \n%     \\setlength{\\leftmargin}{#1}% \n%     \\setlength{\\rightmargin}{#2}% \n%     \\setlength{\\listparindent}{\\parindent}% \n%     \\setlength{\\itemindent}{\\parindent}% \n%     \\setlength{\\parsep}{\\parskip}% \n%   }% \n%   \\item[]}{\\end{list}} \n% \\usepackage{bibentry}\n% \\usepackage{biblatex}\n% \\bibliography{foo}\n\\setbeamersize{text margin left=0.5cm}\n% \\usepackage{beamerthemebars}\n% \\usepackage[bars]{beamerthemetree}\n% \\setbeamercovered{higly dynamic}\n%% ================== block: Information ==========================\n% \\setbeamertemplate{footline}[body]\n% \\title[]{DFDL: \\\\Discriminative Feature-oriented \\\\Dictionary Learning \\\\for Histopathological Image Classification}\n% \\subtitle{}\n% \\author[]{\\small Tiep Huu Vu\\\\ \\tcb{Master Paper Presentation}\\\\\n% \\vspace{3mm} \\includegraphics[scale=0.3]{figs/ipal.png}  }\n\n% \\date[]{\n% \\vspace{3mm} April 9, 2015}\n% \\institute[]{Department of Electrical Engineering \\\\  \\vspace{2mm}Pennsylvania State University }\n%% ------------------end of block: Information ----------------------------\n\n\\def\\changemargin#1#2{\\list{}{\\rightmargin#2\\leftmargin#1}\\item[]}\n\\let\\endchangemargin=\\endlist \n\n\n\\setbeamertemplate{navigation symbols}{}\n\n  %%%%Title Slide{\n\\title[Discriminative Dictionary Learning]{Dictionary learning for signal classification \\\\ under sparsity constraints\\\\}\n\\subtitle{}\n\\author[Tiep Huu Vu]{Tiep Vu}\n\\institute {School of Electrical Engineering and Computer Science \\\\ The Pennsylvania State University\\\\ \\vspace{4mm}}\n% Research Supported by:\n% \\begin{changemargin}{1in}{0in} \n% \\begin{itemize}\n% % \\hspace{1in}\n%   \\item Army Research Office grant number W911NF-14-1-0421\n%   \\item National Institute of Health NIH grant KNS070928 \n%   % \\item NCI Cancer Center Support Grant NCI P30 CA016672\n%   % \\item Career Development Award from the Brain Tumor SPORE\n% \\end{itemize}\n% \\end{changemargin} \n\n% }\n\\date[November 2015]{September 13$^{\\text{th}}$, 2017}\n\\titlegraphic{\n\\includegraphics[height=.9cm]{figs/EECS-header.png} ~~~~~~\n\\includegraphics[height=.9cm]{figs/ipal.png}\\hspace*{-.75cm}\\vspace*{0cm}} % instead of \\logo command to only have the logo at the title page\n% \\begin{document}\n\n% {\n% \\begin{frame}[plain]\n%   \\titlepage\n% \\end{frame}\n% }\n% \\addtocounter{framenumber}{-1}  % Start numbering from second slide\n\n%%%%Title Slide}\n\n\n%%%%Outline Slide{\n\n% \\frame\n% {\n%   \\frametitle{Outline}\n%   \\tableofcontents\n% }%%%%Outline Slide}\n%% ========= Begin Document here ==============================\n\\begin{document}\n%----------- titlepage ----------------------------------------------%\n\\begin{frame}[plain]\n  \\titlepage \n\\end{frame}\n% ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{Outline}\n% \\def\\sp{\\vspace{0.2in}}\n% \\begin{enumerate}\n%   \\item Introduction to Histopathological Image Classification Problems.\n%   \\sp\n%   \\item Sparse Representation-based Classification.\n%   \\sp\n%   \\item Discriminative Feature-oriented Dictionary Learning\n%   \\sp\n%   \\item Experimental Results \n%   \\sp\n%   \\item Conclusion\n% \\end{enumerate}\n% \\end{frame}\n\\frame\n{\n  \\frametitle{Outline}\n  \\tableofcontents\n}%%%%Outline Slide}\n\n\\section{Introduction and Motivation} % (fold)\n\\label{sec:introduction_and_motivation}\n% subsection sparse_representation_based_clas (end)\n% ==================================New lide============================================\n% \\begin{frame}\n%   \\frametitle{}\n% \\begin{center}\n% \\large{\\tcb{Motivation: Sparse Representation-Based Classification (SRC)}}\n% \\end{center}\n% \\end{frame}\n\n\\subsection{Sparse Representation} % (fold)\n\\label{sub:motivations}\n% ==================================New Slide============================================\n\\begin{frame}\n\\frametitle{Sparsity in Signal/Image Processing}\n\\begin{itemize}\n  % \\item Parsimony in signal representation has been shown to have value in many applications.\n  \\item A large class of signals can be represented in a compact manner with respect to some basis (dictionary).\n  \\item Recent advances using spare representation for a variety of applications:\n  % \\begin{tabular}{cl}  \n  %       \\begin{tabular}{c}\n  %        \\hspace{-.3in}\n  %       \\parbox{0.7\\linewidth}{\n  %       % \\includegraphics[height=5cm, width=3.5cm]{figs/SRC_fig11.pdf}\n  %           \\begin{itemize}\n  %   \\item Signal and image acquisition\\footnote{\\tiny D. Donoho \\etal, Compressed sensing, TIT 2006}\n  %   % \\item Signal compression\\footnote{\\tiny J. Zepeda, Image compression using sparse representations and the Iteration-tuned and aligned dictionary, Selected topicsin SP, 2011}\n  % \\end{itemize}}\n  %       \\end{tabular}\n  %       & \\begin{tabular}{l}\n  %           \\hspace{-.3in}\n  %           \\includegraphics[width=.3\\textwidth]{pgfs/SRC_extension_slide_v3.pdf}\n  %       \\end{tabular}  \\\\\n  %   \\end{tabular}\n  \\begin{columns}[onlytextwidth]\n  \\begin{column}{.05\\textwidth}    \n  \\end{column}\n  \\begin{column}{.45\\textwidth}\n    \\begin{itemize}\n    \\item Signal and image acquisition\\footnote[frame]{\\tiny D. Donoho \\etal, Compressed sensing, TIT 2006}\n    \\item Signal compression\\footnote[frame]{\\tiny J. Zepeda, Image compression using sparse representations and the Iteration-tuned and aligned dictionary, Selected topics in SP, 2011}\n  \\end{itemize}\n  \\end{column} \n  \\begin{column}{.45\\textwidth}\n    \\begin{itemize}   \n    \\item Signal denoising and inpainting\\footnote[frame]{\\tiny J. Mairal \\etal, Non-local sparse models for image retoration, ICCV 2009 }   \n    \\item Signal classification\\footnoteSRC.\n  \\end{itemize}\n  \\end{column}\n\\end{columns}  \n\\end{itemize}\n%-------------------------------------------------------------------\n%    Include graphic    \n%-------------------------------------------------------------------  \n\\begin{center}    \n   % \\includegraphics[scale=0.6]{figs/dctvslearn.png}\n   \\includegraphics[scale=0.7]{figs/p1.png}\n\\end{center}\n\\end{frame}\n\n% subsection motivations (end)\n% ==================================New Slide============================================\n% \\subsection{Sparse Representation} % (fold)\n% \\label{sub:sparse_representation}\n\n% subsection sparse_representation (end)\n% \\begin{frame}\n% \\frametitle{Sparse Representation - Mathematical Model}\n% \\begin{figure}[ht]\n%   % \\only<1>{\\includegraphics[width = .9\\textwidth]{pgfs/sparseRepresentation_slide0.pdf}}\n%   \\only<1>{\\includegraphics[width = .9\\textwidth]{pgfs/sparseRepresentation_slide.pdf}}\n% \\end{figure}\n% \\end{frame}    \n\n\n% ==================================New Slide============================================\n\\subsection{Sparse Representation-based Classification} % (fold)\n\\label{sec:sparse_representation_based_clas}\n\n% section sparse_representation_based_clas (end)\n\\begin{frame}\n% \\setcounter{footnote}{0}\n  \\frametitle{SRC\\footnoteSRC - Robust Face Recognition via Sparse Representation}\n\\vspace{-2mm}\n\\begin{figure}\n  \\centering\n  % \\includegraphics[scale=0.45]{figs/SRC_fig11.pdf}\n  \\includegraphics[width = \\textwidth]{pgfs/SRC_idea.pdf}\n  \\vspace{-2mm}\n\\end{figure}\n% \\centering SRC is claimed to be robust to noise and occlusions.\n\\end{frame}\n\n%----------- slide --------------------------------------------------%\n% \\subsection{Sparse Representation-based Image Classification} % (fold)\n% \\label{sub:sparse_representation_based_image_classification}\n\n% % subsection sparse_representation_based_image_classification (end)\n% \\begin{frame}\n% \\setcounter{footnote}{5}\n%   \\frametitle{Sparse Representation-based Image Classification\\footnoteSRC}\n% \\begin{itemize}\n%   \\item Extension of CS analytical framework to classification by designing \\tcb{class-specific} dictionaries\n% \\end{itemize}\n% \\begin{figure}\n%   \\centering\n%   \\includegraphics[width = \\textwidth]{pgfs/src_vis.pdf}\n% \\end{figure}\n\n% \\end{frame}\n\n%----------- slide --------------------------------------------------%\n\\begin{frame}\n\\label{sli:SRC_classification}\n\\setcounter{footnote}{1}\n  \\frametitle{Sparse Representation-based Image Classification\\footnoteSRC}\n\\begin{itemize}\n  \\item Given: $C$ classes and the total dictionary:\n  $$\\bD = \\bmt \\bD_1 &\\dots & \\bD_j & \\dots & \\bD_C\\emt.$$\n  % \\medskip\n  \\item Classification scheme for a new test image $\\by:$\n    \\begin{itemize}\n      \\item The sparse code $\\bx$ is found via $l_1-$norm minimization:\n      \\begin{equation}\n      \\bx = \\arg\\min_{\\bx} \\|\\by - \\bD\\bx\\|_2^2 + \\lambda\\|\\bx\\|_1.\n      \\end{equation}\n    \\end{itemize}\n     %-------------------------------------------------------------------\n     %    Include graphic    \n     %-------------------------------------------------------------------  \n     % \\vspace{-1in}\n     \\begin{center}    \n     \\vspace{-0.3in}\n     % \\hspace{-1cm}\n        \\includegraphics[width =1\\textwidth]{pgfs/SRC_original_idea_2.pdf}\n     \\end{center}\n     \\vspace{-0.3in}\n     \n    \\begin{itemize}\n      \\item Membership of $\\by$ is determined based on minimum residual:\n      \\begin{equation}\n       \\text{id}(\\by) = \\arg\\min_{i = 1, 2, \\dots, C} \\|\\by - \\bD_i\\bx^i\\|_2.\n      \\end{equation}\n    \\end{itemize} \n  \\end{itemize}\n\\end{frame}\n\n\\begin{frame}  \n\\frametitle{SRC - Pros, Cons and Extensions}\n    \\begin{tabular}{cl}  \n        \\begin{tabular}{c}\n         \\hspace{-.3in}\n        \\parbox{0.7\\linewidth}{\n        % \\includegraphics[height=5cm, width=3.5cm]{figs/SRC_fig11.pdf}\n            \\begin{itemize}\n                \\item \\tcb{Pros:}\n                    \\begin{itemize}\n                        \\item Shows significant performance with abundant training. %Suffers from low training scenarios.\n                        \\item SRC is robust to high amount of noise and occlusion.\n                    \\end{itemize}\n                \\item \\tcb{Cons}: \n                    \\begin{itemize}\n                        \\item  Does not exploit of intra class and inter class structures.\n                        \\item With high training, the raw-combined dictionary is \\textbf{redundant} and required \\textbf{high computation time}.\n                    \\end{itemize} \n                \\medskip\n                \\item \\tcb{Extensions:} \n                    \\begin{itemize}\n                        \\item Structured sparse coding: LLC\\footnoteLLC, JSRC\\footnoteJSRC, JDSRC\\footnoteJDSRC, SHIRC\\footnoteSHIRC.\n                        \\item Dictionary Learning for compacting data and capturing signal structures.\n                    \\end{itemize}\n            \\end{itemize}}\n        \\end{tabular}\n        & \\begin{tabular}{l}\n            \\hspace{-.3in}\n            \\includegraphics[width=.3\\textwidth]{pgfs/SRC_extension_slide_v3.pdf}\n        \\end{tabular}  \\\\\n    \\end{tabular}\n\\end{frame}\n\n% \\input{src_Hojjat}\n% ==================================New Slide============================================\n\\subsection{Dictionary Learning} % (fold)\n\\label{sub:dictionary_learning_for_clas}\n\n% subsection dictionary_learning_for_clas (end)\n% ==================================New Slide============================================\n\\begin{frame}\n\\frametitle {Dictionary Learning - previous works}\n    \\begin{itemize}\n      \\item For compacting each sub-dictionary $\\bD_i$: \n      \\begin{itemize}\n      \n      \\item K-SVD\\footnoteKSVD:\n      \\begin{equation}\n          (\\bD, \\bX) = \\arg\\min_{\\bD, \\bX} \\|\\bY - \\bD\\bX\\|_F^2 \\text{~subject to:~} \\|\\bx_i\\|_0 \\leq L\n      \\end{equation}\n      \\item On-line Dictionary Learning\\footnoteODL (ODL).\n      \\begin{equation}\n          (\\bD, \\bX) = \\arg\\min_{\\bD, \\bX} \\|\\bY - \\bD\\bX\\|_F^2 + \\lambda \\|\\bX\\|_1\n      \\end{equation}\n      \\end{itemize}\n      and implicit contraint: $\\|\\bd_j\\|_2^2 = 1.$\n      \\medskip\n      \\item For classification (combined with structures and discriminative constraints): \n      \\vspace{-0.3cm}\n        \\begin{itemize}\n            \\item Locality-constrained linear coding (LLC\\footnoteLLC),\n            \\item Discriminative-KSVD\\footnoteDKSVD, \n            \\item Label-Consistent KSVD\\footnoteLCKSVD,\n            \\item Fisher Discriminant Dictionary Learning\\footnoteFDDL,\n            \\item and many others.\n        \\end{itemize}\n    \\end{itemize}\n    \\vspace{2mm}\n\\end{frame}\n\n% section introduction_and_motivations (end)\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n%% ================== block: DFDL ==========================\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n    \n\n\\section{Part I: DFDL} % (fold)\n\\label{sec:contribution_i_dfdl}\n\n% section contribution_i_dfdl (end)\n\\begin{frame}\n  \\frametitle{}\n\\begin{center}\n\\large{\\tcb{Part I\\\\DFDL: Discriminative Feature-oriented Dictionary Learning }}\n\\end{center}\n\\medskip\n\\medskip\n{\\small \nRelated publications:\n\\begin{enumerate}\n  \\item  Tiep Vu, Vishal Monga, \\etal ``DFDL:  Discriminative Feature-oriented Dictionary Learning for Histopathological Image Classification.'' In {\\bf IEEE International Symposium on Biomedical Imaging (ISBI)}, April 2015.\n  \\item Tiep Vu, Vishal Monga, \\etal ``Histopathological Image Classification using Discriminative Feature-oriented Dictionary Learning''. {\\bf IEEE Transactions on Medical Imaging}, March 2016.\n\\end{enumerate}}\n\\end{frame}\n% ==================================New Slide============================================\n\\subsection{Main idea} % (fold)\n\\label{sub:main_idea}\n\n% subsection main_idea (end)\n\\begin{frame}\n\\frametitle{Main Idea}\n\\setcounter{footnote}{6}\n% \\begin{itemize}\n  % \\item From one-vs-rest perspective:\n% \\end{itemize}\n% \\vspace{-0.2in}\n% \\vspace{-0.2in}\n  % \\tcb{a)} Learned bases using in-class samples (e.g. K-SVD\\footnoteKSVD , ODL\\footnoteODL): may also cover some complementary samples.\\\\\n  % \\tcb{b)} Desired DFDL bases: cover in-class samples only.\\\\\n \\begin{itemize}\n    \\item {A \\textbf{class-specific} dictionary $\\bD$ \\tcb{\\textbf{sparsely expresses in-class samples}} ($\\bY$): $$\\min_{\\|\\bs\\|_0 \\leq L} \\frac{1}{N}\\|\\bY - \\bD\\bX\\|_F^2 \\text{~small}.$$}\n    \\item {But it is \\tcb{\\textbf{incapable of expressing complementary samples}} ($\\bar{\\bY}$) with small number of bases: $$\\displaystyle\\min_{\\|\\bar{\\bx}\\|_0 \\leq L} \\frac{1}{\\bar{N}}\\|\\bar{\\bY} - \\bD\\bar{\\bX}\\|_F^2 \\text{~~large}$$ }\n  \\end{itemize}\n\\vspace{-0.1in}\n\\begin{figure}[t]\n\\centering\n  \\includegraphics[width=0.65\\textwidth]{pgfs/idea4.pdf}\n  \\label{fig: idea}\n\\end{figure}\n\\end{frame}\n% ==================================New Slide============================================\n\\subsection{Problem formulation} % (fold)\n\\label{sub:problem_fomu}\n\n% subsection problem_fomu (end)\n% ==================================New Slide============================================\n\\begin{frame}%[1-3]\n\\setcounter{footnote}{6}\n\\frametitle{Problem formulation (per class)}\n\\tcb{Goal:} $\\quad \\displaystyle \\frac{ 1  } { N } \\min_{   \\|\\bX\\|_0 \\leq L }\\|\\bY - \\bD \\bX\\|_F^2 \\ll\\displaystyle \\frac{ 1  } { \\bar{N} } \\min_{\\|\\bar{\\bX}\\|_0 \\leq L}\\|\\bar{\\bY} - \\bD \\bar{\\bX}\\|_F^2$\n\\begin{tcolorbox}[colback=white!10,colframe=blue!55!black,title=DFDL Optimization problem ]\n\\vspace{-0.2in}\n\\begin{equation*}\n    (\\bD, \\bX, \\bar{\\bX})= \\arg \\min _{\\bD, \\bX, \\bar{\\bX}} \\Big(\\frac{ 1  } { N }\\min_{\\|\\bX\\|_0 \\le L}\\|\\bY - \\bD \\bX\\|_F^2\n   - \\frac{ \\rho  } { \\bar{N} } \\min_{\\|\\bar{\\bX}\\|_0 \\le L}\\|\\bar{\\bY} - \\bD \\bar{\\bX}\\|_F^2 \\Big)\n\\end{equation*}\n\\begin{center}\n        subject to: $\\|\\bd_j\\|_2^2 = 1$\n    \\end{center}\n\\end{tcolorbox}\n\\vspace{-0.05in}\n       $\\rho$ is a positive regularization parameter.\n       \\vspace{0.1in}\n  \\begin{itemize}\n    \\item {$L$ (sparsity level) is obtained from ODL\\footnoteODL}:\n    \\begin{equation}\n        (\\bD^0, \\bX^0) = \\arg\\min_{\\bD, \\bX} \\|\\bY - \\bD\\bX\\|_F^2 + \\lambda\\|\\bX\\|_1; \\text{choose:} L \\approx \\frac{\\sum_{i=1}^N\\|\\bx_i^0\\|_0}{N}\n    \\end{equation}\n      \\item $\\bD, \\bX, \\bar{\\bX}$ can be found by alternately solving: \\\\\n    % \\begin{enumerate}\n      1. Fix $\\bD$, find $\\bX, \\bar{\\bX}$   $~~~~~~~~~~~~~~~~~$    2. Fix $\\bX, \\bar{\\bX}$, find $\\bD$% by solving:\n    % \\end{enumerate}\n  \\end{itemize}\n\\end{frame}\n\n% % ==================================New Slide============================================\n\n% % ==================================New Slide============================================\n\\begin{frame}\n\\frametitle{$\\bX, \\bar{\\bX}$ update}\n\n% \\begin{tcolorbox}[colback=white!10,colframe=blue!55!black,title= Solving  ]\n%   \\begin{equation}\n%       \\bX^* = \\arg \\min_{\\|\\bX\\|_0 \\leq L} \\|\\bX - \\bD\\bX\\|_F^2, \\quad \\bar{\\bX}^* = \\arg\\min_{\\|\\bar{\\bX}\\|_0 \\leq L} \\|\\bar{\\bY} - \\bD\\bar{\\bX}\\|_F^2\n%   \\end{equation}\n% \\end{tcolorbox}\n\n\\begin{enumerate}\n  \\item fix $\\bD$, find $\\bX, \\bar{\\bX}$.\n   % \\begin{equation*}\n       \\begin{equation}\n          \\bX = \\arg \\min_{\\|\\bX\\|_0 \\leq L} \\|\\bY - \\bD\\bX\\|_F^2, \\quad \\bar{\\bX} = \\arg\\min_{\\|\\bar{\\bX}\\|_0 \\leq L} \\|\\bar{\\bY} - \\bD\\bar{\\bX}\\|_F^2\n      \\end{equation}\n      % \\pause\n      Combine them into one problem:\n      \\begin{tcolorbox}[colback=white!10,colframe=blue!55!black,title= Solving  $\\hat{\\bX}$]\n      % asfd\n         \\begin{equation}\n          \\label{eqn:findShat}\n            \\hat{\\bX} = \\arg\\min_{\\|\\hat{\\bX}\\|_0 \\leq L} \\| \\hat{\\bY} - \\bD \\hat{\\bX}\\|_F^2\n          \\end{equation}\n      \\end{tcolorbox}    \n      where $\\hat{\\bY} = \\big[\\bY, \\bar{\\bY} \\big]$, $ \\hat{\\bX} = \\big[ \\bX, \\bar{\\bX} \\big]$\n      \n      \\vspace{0.5cm}\n      Problem (\\ref{eqn:findShat}) can be solved effectively by Orthogonal Matching Pursuit\\footnoteOMP~  algorithm using mexOMP\\setcounter{footnote}{14}\\footnote{\\tiny  \\href{http://spams-devel.gforge.inria.fr/}{SPAMS - SPArse Modeling Software}}.\n\\end{enumerate}\n\\end{frame}\n% ==================================New Slide============================================\n\\begin{frame}\n\\setcounter{footnote}{7}\n\\frametitle{$\\bD$ update}\n% \\begin{enumerate}\n%   \\item fix $\\bX, \\bar{\\bX}$, find $\\bD$% by solving:\n% \\end{enumerate}\n{\\small\n\\begin{enumerate}\n  \\setcounter{enumi}{1}\n  \\item fix $\\bX, \\bar{\\bX}$, find $\\bD$% by solving:\n  % \\begin{tcolorbox}[colback=white!10,colframe=blue!55!black,title= Solving $\\bD$ ]\n    \\begin{eqnarray}\n    \\nonumber\n       \\bD^* &=& \\arg\\min_{\\bD} \\Big\\{ \\frac{ 1  } { N } \\|\\bY - \\bD\\bX\\|_F^2 - \\frac{ \\rho } { \\bar{N} } \\|\\bar{\\bY} - \\bD\\bar{\\bX}\\|_F^2 \\Big\\} \\\\\n       % \\pause\n              & = & \\arg\\min_{\\bD} \\big\\{-2\\trace(\\bE \\bD^T) + \\trace(\\bD \\Fb \\bD^T) \\big\\}\\\\\n              \\label{eqn:dd1}\n        &&\\text{subject to}: \\|\\bd_j\\|_2^2 = 1\n    \\end{eqnarray}\n    % \\begin{center}\n    % \\end{center}\n  % \\end{tcolorbox}\n    where:\n      \\begin{eqnarray*}\n        \\bE = \\frac{ 1 } { N } \\bY \\bX^T - \\frac{ \\rho } { \\barN } \\bar{\\bY}\\bar{\\bX}^T; \\quad\n        \\Fb = \\frac{ 1  } { N } \\bX \\bX^T - \\frac{ \\rho } { \\barN } \\bar{\\bX} \\bar{\\bX}^T \\text{(maybe not PSD)}\n      \\end{eqnarray*}\n      \\begin{itemize}\n        \\item       $f(\\bD) = -2\\trace(\\bE \\bD^T) + \\trace(\\bD \\Fb \\bD^T$) is convex $\\Leftrightarrow$ $\\Fb$ is PSD.\\\\\n      \\pause\n      \\item \\tcb{Trick}: $\\trace\\left({\\bD\\lambda_{\\min}(\\Fb)\\bD^T}\\right) = \\lambda_{\\min}(\\Fb)\\trace(\\bD^T\\bD) = \\text{\\tcb{constant}}$ since (\\ref{eqn:dd1}).\n      \\end{itemize}\n      \\begin{tcolorbox}[colback=white!10,colframe=blue!55!black,title= Revised problem for solving $\\bD$ with \\textbf{convex} objective function ]\n        \\vspace{-0.1in}\n        \\begin{equation}            \n        \\bD= \\arg\\min_{\\bD} \\big\\{-2\\trace(\\bE \\bD^T) + \\trace(\\bD (\\Fb - \\lambda_{\\min}(\\Fb) \\mathbf{I}) \\bD^T)  \\big\\}\n        \\end{equation}\n  \\end{tcolorbox}\n       As \\tcb{$\\Fb - \\lambda_{\\min}(\\Fb)\\bI $ is PSD}, $\\bD$ can be found by method proposed in ODL\\footnoteODL.\n\\end{enumerate}\n}\n\\end{frame}\n% ==================================New Slide============================================\n\\begin{frame}\n\\setcounter{footnote}{7}\n\\vspace{-0.1in}\n\\frametitle{DFDL Algorithm (for each class-specific dictionary)}\n\n{\\small \\begin{algorithm}[H]\n  \\begin{algorithmic}[0]\n    \\STATE \\tb{INPUT:} {$\\bY, \\bar{\\bY}$. $k$: number of learned bases.$\\rho$: regularization parameter}. \n    \\STATE 1. Initial $L$ and $\\bD$ by ODL\\footnoteODL (with in-class samples $\\bY$ only)\n      \\WHILE{not converged}\n        \\STATE 2. Fix $\\bD$ and update $\\bX, \\bar{\\bX}$ by solving an OMP\\footnoteOMP~ problem; \\\\\n        \\STATE 3. Fix $\\bX, \\bar{\\bX}$, calculate: \n        \\begin{equation*}\n            \\bE = \\frac{ 1 } { N } \\bY \\bX^T - \\frac{ \\rho } { \\bar{N} } \\bar{\\bY}\\bar{\\bX}^T; \\quad\n             \\Fb = \\frac{ 1  } { N } \\bX \\bX^T - \\frac{ \\rho } { \\bar{N} } \\bar{\\bX} \\bar{\\bX}^T.\n        \\end{equation*}    \n        % \\IF {$\\Fb$ is not PSD}\n        %   \\STATE $\\rho \\leftarrow 0.9\\rho$; \\textbf{go to} 3\n        % \\ENDIF\n         \\STATE 4. {Update $\\bD$ from: $$\\bD= \\arg\\min_{\\bD} \\big\\{-2\\trace(\\bE \\bD^T) + \\trace(\\bD (\\Fb - \\lambda_{\\min}(\\Fb) \\mathbf{I}) \\bD^T)  \\big\\}$$}\n      \\ENDWHILE\n      \\STATE \\tb{RETURN:} $\\bD$\n    \\end{algorithmic}\n    % \\caption{DFDL}\n    \\label{alg:seq}\n  \\end{algorithm}}\n  \\vspace{-0.3cm}\n  % Classification scheme: Similar to SRC. (\\textcolor{white}{Slide \\ref{sli:SRC_classification}}.)\n  Classification scheme: Similar to SRC (minimum residual). \\textcolor{white}{\\ref{sli:SRC_classification}}\n\\end{frame}\n\n\n\\subsection{DFDL applications} % (fold)\n\\label{sub:dfdl_applications}\n\n% subsection dfdl_applications (end)\n% ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{Applying DFDL to Histopathological Image Classification}\n% % \\centering\n\n%   \\includegraphics[width =1\\textwidth]{pgfs/examples_landscape.pdf}\\\\\n% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n% %% ================== block:  ==========================\n% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%  \\begin{tabular}{cl}  \n%   \\begin{tabular}{c}\n%      \\hspace{-.3in}\n%       \\parbox{0.5\\linewidth}{\n%         {\\small \n%           Three different histopathological datasets:\n%           \\begin{itemize}\n%           \\item {\\tcb{IBL}} -  Intraductal Breast Lesions.\n%           \\item {\\tcb{ADL}} - Animal Diagnostic Laboratory: Kidney, Lung and Spleen.\n%           \\item {\\tcb{TCGA}} - The Cancer Genome Atlas: Glioblastoma Multiforme.\n%           \\end{itemize}\n%         }\n%        }\n%    \\end{tabular}\n%    & \n%    \\begin{tabular}{l}\n%       % \\hspace{-.3in}\n%       \\parbox{0.45\\linewidth}{\n%         {\\small \n%           \\textbf{\\tcb{Challenges}}:\n%           \\begin{itemize}\n%             \\item \\tcb{Diversity} of histology features suitable for each problem\n%             \\item Presence of \\tcb{rich geometrical} structures\n%           \\end{itemize}\n%         }\n%       }\n%   \\end{tabular}  \n% \\end{tabular}    \n% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n% %% ------------------end of block:  ----------------------------\n% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n% \\end{frame}\n\n\\begin{frame}\n\\frametitle{Applying DFDL to Histopathological Image Classification}\n% \\centering\n\n  \\includegraphics[width =1\\textwidth]{}\n  \n \\begin{tabular}{cl}  \n  \\begin{tabular}{c}\n     \\hspace{-.3in}\n      \\parbox{0.5\\linewidth}{\n        {\\small \n          Two histopathological datasets:\n          \\begin{itemize}\n          \\item {\\tcb{IBL}} -  Intraductal Breast Lesions.\n          \\item {\\tcb{ADL}} - Animal Diagnostic Laboratory: Kidney, Lung and Spleen.\n          % \\item {\\tcb{TCGA}} - The Cancer Genome Atlas: Glioblastoma Multiforme.\n          \\end{itemize}\n        }\n       }\n   \\end{tabular}\n   & \n   \\begin{tabular}{l}\n      % \\hspace{-.3in}\n      \\parbox{0.45\\linewidth}{\n        {\\small \n          \\textbf{\\tcb{Challenges}}:\n          \\begin{itemize}\n            \\item \\tcb{Diversity} of histology features suitable for each problem\n            \\item Presence of \\tcb{rich geometrical} structures\n          \\end{itemize}\n        }\n      }\n  \\end{tabular}  \n\\end{tabular}    \n\\end{frame}\n\n\n% ==================================New Slide============================================\n% s\n%% ================================================== end ==============================\n\n% % ==================================New Slide============================================\n\\begin{frame}\n\\frametitle{Example bases learned from different DL methods}\n% \\vspace{-0.1in}\n% \\Wider{\n\\AtBeginNote{\\hspace*{-10pt}\\addtolength\\leftmargini{-10pt}}\n\\AtEndNote{\\addtolength\\leftmargini{10pt}}\n\\begin{figure}\n  % \\centering\n\\vspace{-0.25cm}\n    \\includegraphics[width = \\textwidth]{pgfs/visualizeDict4_tmi.pdf}\n    % \\caption{{\\small Example bases from different DL methods}}\n  \\label{fig:dictIK}\n\\end{figure}\n\\vspace{-0.45cm}\n\\begin{itemize}\n  \\item DFDL is able to look for discriminative visual features.\n  \\item LC-KSVD\\footnoteLCKSVD bases do not present key properties of each class, e.g. Lung.\n  \\item FDDL\\footnoteFDDL fails to discover discriminative visual features that are interpretable\n\\end{itemize}\n\n\\end{frame}\n% ==================================New Slide============================================\n\n% \\begin{frame}\n% \\frametitle{Toy example - Compare DFDL to LC-KSVD sparse coeffs}\n% \\includegraphics[width = \\textwidth]{pgfs/visual_coef_combine.pdf}\n% \\begin{itemize}\n%   \\item LC-KSVD coeffs are nearly \\tcb{equally distributed in both classes}.\n%   \\item Most of DFDL coeffs are \\tcb{gathered in the corresponding class}. \n% \\end{itemize}\n% \\end{frame}\n% ==================================New Slide============================================\n\\begin{frame}\n\\frametitle{IBL/ADL classification result (1)}\n\\vspace{-0.1in}\n\\noindent\n\\begin{figure}[ht]\n  % \\centering\n  \\includegraphics[width = 0.8\\textwidth]{pgfs/Results_slide3.pdf}\n  % \\includegraphics[scale=0.7]{slides/adltable2.pdf}\n  % \\caption{Accuracy ($\\%$) over number of training patches}\n  \\label{fig: compare_nimgs}\n\\end{figure}\n\n\\end{frame}\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{IBL/ADL classification result (2)}\n% \\vspace{-0.1in}\n% \\begin{figure}[ht]\n%   \\centering\n%   % \\includegraphics[scale=0.6]{pgfs/Results.pdf}\n%   \\includegraphics[width = \\textwidth]{pgfs/Results_slide2.pdf}\n%   % \\caption{Accuracy ($\\%$) over number of training patches}\n%   \\label{fig: compare_nimgs}\n% \\end{figure}\n%  $\\Rightarrow$ DFDL performs well even with limited training.\n\n% \\end{frame}\n% ==================================New Slide============================================\n\\begin{frame}\n\\frametitle{The Cancer Genome Atlas - MVP detection problem}\n\\begin{center}  \n\\includegraphics[width = .8\\textwidth]{pgfs/examples_TCGA.pdf}\n\\end{center}\nMVP:\n\\begin{itemize}\n  \\item is the presence of blood vessels in a tissue,\n  \\item is an important indicator of HGG.\n  \\item Detecting MVP regions is a challenging problem\\footnoteHojjatJPI.\n\\end{itemize}\n\\vspace{1mm}\n\\end{frame}\n% % ==================================New Slide============================================\n\\begin{frame}\n\\vspace{-.15cm}\n% \\newgeometry{ right = -0.5cm}\n\\frametitle{TCGA classification procedure (MVP detection)}\n\\begin{figure}\n  % \\includegraphics[width = .95\\textwidth]{pgfs/tcga_poster.pdf}\n  \\includegraphics[width = .9\\textwidth]{pgfs/tcga_poster_Nov28.pdf}\n\\end{figure}\n\\end{frame}\n% ==================================New Slide============================================\n\\subsection{Complexity analysis} % (fold)\n\\label{sub:complexity_analysis}\n\\begin{frame}\n\\frametitle{Complexity Analysis for different DL methods}\n\\vspace{-.15cm}\n\\begin{table}[t]\n\\centering\n% \\caption{ {Complexity analysis for different dictionary learning methods.}}\n\\label{tab:complexity}\n  \\begin{tabular}{|l|l|l|}\n  \\hline\n  Method & Complexity & Running time \\\\ \\hline\n  DFDL &$C^2kN(2d + L^2)$  & $\\sim$ 0.5 hours\\\\ \\hline\n  LC-KSVD\\footnoteLCKSVD & $C^2kN(2d + 2Ck + L^2)$& $\\sim$ 3 hours \\\\ \\hline\n  Nayak's \\etal \\footnoteNANDITA &$C^2kN(2d + 2qCk) + C^2dk^2$& $\\sim$ 8 hours \\\\ \\hline\n  FDDL\\footnoteFDDL & $C^2kN(2d + 2qCk) + C^3dk^2$& $>$ 40 hours\\\\ \\hline\n  \\end{tabular}\n  % \\begin{tablenotes}\n  %     \\small\n  %     \\item $^{(*)}$$q$ is the number of iterations required for $l_1$-minimization in sparse coding step.\n  %   \\end{tablenotes}\n\\end{table}\n$C = 2, k = 500, d = 1200, L = 30, N = 10000:$\n% \\vspace{-.25cm}\n\\begin{table}[t]\n\\centering\n% \\caption{Estimated number of operations required in different dictionary learning methods.}\n% \\label{tab:operations}\n  \\begin{tabular}{|l|l|l|l|}\n  \\hline\n  Method &  $q = 1$ &  $q = 3$        &              $q = 10$\\\\ \\hline\n  DFDL      & $6.6 \\times 10^{10}$    & $6.6 \\times 10^{10}$    & $6.6 \\times 10^{10}$    \\\\ \\hline\n  LC-KSVD  & $1.06 \\times 10^{11}$   & $1.06 \\times 10^{11}$   & $1.06 \\times 10^{11}$   \\\\ \\hline\n  Nayak's \\etal    & $8.92\\times 10^{10}$    & $1.692 \\times 10^{11}$  & $4.492 \\times 10^{11}$\\\\ \\hline\n  FDDL      & $9.04 \\times 10^{10}$   & $1.704 \\times 10^{11}$  & $4.504 \\times 10^{11}$\\\\ \\hline\n  \\end{tabular}\n\\end{table}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n%% ================== block:  ==========================\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\\vspace{-0.1in}\n \\begin{tabular}{cl}  \n  \\begin{tabular}{c}\n     \\hspace{-.1in}\n      \\parbox{0.45\\linewidth}{\n        {\\small \n          \\begin{itemize}\n          \\item $C$: \\#classes.\n          \\item $k$: \\#atoms in EACH dictionary.\n          \\item $N$: \\#training patches in EACH class.          \n          \\end{itemize}\n        }\n       }\n   \\end{tabular}\n   & \n   \\begin{tabular}{l}\n      \\hspace{-.3in}\n      \\parbox{0.52\\linewidth}{\n        {\\small \n          \\begin{itemize}\n          \\item $d$: data dimension.\n          \\item $L$: sparsity level (DFDL, LC-KSVD).\n          \\item $q$: \\#iterations required for $l_1$-minimization (FDDL, Nayak's \\etal).\n          \\end{itemize}\n        }\n      }\n  \\end{tabular}  \n\\end{tabular}    \n\\end{frame}\n\n% ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{DFDL - conclusion}\n\n% \\begin{itemize}\n%   \\item Extracts features automatically,\n%   \\item Performs better other state-of-the-art methods in histopathological image datasets,\n%   \\item Could be applied to several histopathological image problems,\n%   \\item Low complexity,\n%   \\item Performs well even with low training.\n% \\end{itemize}\n% \\end{frame}\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n%% ------------------end of block:  ----------------------------\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   \n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n%% ------------------end of block: DFDL ----------------------------\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \n% \\input{proposedContributionII}\n\n\n% \\section{Part 2: LRSDL}\n% \\begin{frame}\n%   \\frametitle{}\n% \\begin{center}\n% \\large{\\tcb{Part II: \\\\LRSDL - Low-rank shared Dictionary Learning}}\n% \\end{center}\n% \\begin{enumerate}\n%   \\item Tiep Vu \\etal, ``Learning a low-rank shared dictionary for object classification'', accepted to {\\bf IEEE International Conference on Image Processing (ICIP)}, 2016.\n%   \\item Tiep Vu \\etal, ``Fast low-rank shared dictionary for image classification'', to be submitted to Transactions on Image Processing.\n% \\end{enumerate}\n% \\end{frame}\n% \\subsection{Main idea}\n\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{Recall Sparse Representation-based classification\\footnoteSRC}\n% \\begin{figure}[h!]\n% \\centering\n% \\includegraphics[width = 1\\textwidth]{pgfs/idea1_1.pdf}\n% \\caption{\\small  SRC}\n% \\vspace{-0.1in}\n% \\end{figure}\n% Most of dictionary learning methods have tried to encourage \\tcb{the code matrix $\\bX$ to be block diagonal}.\n% \\end{frame}\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{Basic Idea}\n% \\begin{figure}[h!]\n% \\centering\n% \\includegraphics[width = 0.8\\textwidth]{pgfs/idea1_2.pdf}\n% \\end{figure}\n% \\end{frame}\n% % ==================================New Slide============================================\n% \\subsection{Problem formulation} % (fold)\n% \\label{sub:problem_formu}\n% % subsection problem_formu (end)\n% \\begin{frame}\n% \\frametitle{LRSDL - Idea visualization}\n% % \\hspace{-0.1cm}\n% \\includegraphics[width =1\\textwidth]{pgfs/idea_SDDL_2.pdf}\\\\\n% % {\\small Without \\tcr{red terms}, SDDL becomes FDDL.}\n% \\end{frame}\n% % ==================================New Slide============================================\n\n% % ==================================New Slide============================================\n% \\subsection{Solution} % (fold)\n% \\label{sub:solution}\n\n% % subsection solution (end)\n% \\begin{frame}\n% \\frametitle{Solution to LRSDL} \n% % \\hspace{-0.2cm}\n\n% % Don't waste you time on adjusting, it's perfect now\n% \\includegraphics[width =1\\textwidth]{pgfs/SDDL_solution1.pdf}\n\n% \\end{frame}\n\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{SDDL - Solving $\\bX$} \n% \\vspace{-0.1in}\n% \\includegraphics[width =1\\textwidth]{pgfs/SDDL_solution2.pdf}\n\n% \\end{frame}\n\n% % ==================================New Slide============================================\n\n% \\begin{frame}\n% \\frametitle{SDDL - Initialization}\n% The better initial guesses, the faster and more accurate the solution:\n% \\begin{itemize}\n%     \\item Initializing $\\bD_i$ and $\\bX_i^i$, $i = 1, 2, \\dots, C$:\n%     \\begin{equation*}\n%         (\\bD_i, \\bX_i^i) = \\arg\\min_{\\bD_i, \\bX_i^i} \\|\\bY_i - \\bD_i\\bX_i^i\\|_F^2 + \\lambda_1 \\|\\bX_i^i\\|_1 + \\lambda_2\\|\\bX_i^i - \\bM_i^i\\|_F^2\n%     \\end{equation*}\n%     \\item Initializing $\\bD_0$ and $\\bX^0$:\n%     \\begin{equation*}\n%         (\\bD_0, \\bX^0) = \\arg\\min_{\\bD_0, \\bX_0} \\|\\bY - \\bD_0\\bX^0\\|_F^2 + \\lambda_1 \\|\\bX^0\\|_1 + \\lambda_2 \\|\\bX^0 - \\bM^0\\|_F^2 + \\eta \\|\\bD_0\\|_*\n%     \\end{equation*}\n\n%     \\item $\\bX^j_i, j \\neq i$ are set to $\\mathbf{0}$.\n% \\end{itemize}\n% \\end{frame}\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{SDDL - Classification scheme}\n% Given the class-specific dictionaries $\\bD_i$, the shared dictionary $\\bD^0$, and the mean vectors $ \\bm_1, \\dots, \\bm_C, \\bm^0$, for a new signal $\\by$:\n% \\begin{itemize}\n%     \\item The sparse code $(\\bx, \\bx^0)$ are found via:\n%     \\begin{equation*}\n%         \\boxed{(\\bx, \\bx^0) = \\arg\\min_{\\bx, \\bx^0} \\|\\by - \\bD_0\\bx^0 - \\bD\\bx\\|_2^2 + \\lambda_2\\|\\bx^0 - \\bm^0\\|_2^2 + \\lambda_1 \\norm{\\bmt \\bx \\\\ \\bx^0\\emt}_1}\n%     \\end{equation*}\n%     by FISTA\\footnoteFISTA.\n%     \\item Let $\\bar{\\by} = \\by - \\bD_0\\bx^0$, the identity of $\\by$ is determined as:\n%     \\begin{equation*}\n%         \\boxed{\\text{id}(\\by) = \\arg\\min_{1 \\leq i \\leq C} \\left(w\\|\\bar{\\by} - \\bD_i\\bx^i\\|_2^2 + (1-w)\\|\\bx - \\bm_i\\|_2^2 \\right)}\n%     \\end{equation*}\n%     where $w \\in (0, 1)$ is a preset weight to balance the contribution of the two terms.\n% \\end{itemize}\n% \\end{frame}\n\n    \n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{Applications to object classification in four datasets }\n% \\begin{center}\n  \n% \\includegraphics[width = .8\\textwidth]{pgfs/examples_4databases.pdf}\n% \\end{center}\n\n% \\end{frame}\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{Preliminary results}\n% \\begin{table}[]\n% \\centering\n% \\caption{The recognition rates (\\%) of various methods on 4 popular databases}\n% \\label{my-label}\n% \\begin{tabular}{|l|c|c|c|c|}\n% \\hline\n% Method                  & AR Face    & Caltech101 & Fifteen Scene & Extended YaleB \\\\ \\hline\n\n% SRC\\footnoteSRC         & 97.5       & 70.7       & 91.8          & 97.2           \\\\ \\hline\n% LC-KSVD\\footnoteLCKSVD  & 97.8       & 73.6       & 92.9          & 96.7           \\\\ \\hline\n% FDDL\\footnoteFDDL       & -          & -          & -             & 97.24          \\\\ \\hline\n% LLC\\footnoteLLC         & 88.7       & 73.44      & 89.2          & -              \\\\ \\hline\n% GDDL\\footnoteGDDL       & 96.7       & 73.6       & -             & 98.2           \\\\ \\hline\n% DL-COPAR\\footnoteDLCORPA & -          & {\\bf 83.26}      & 85.37         & 98.3           \\\\ \\hline\n% HSDDL                   & {\\bf -}    & -          & 79.24         & {\\bf 98.6}           \\\\ \\hline\n% \\tcr{SDDL}                    & {\\bf 98.7} & 72.1       & {\\bf 93.95}   & 98.0           \\\\ \\hline\n% \\end{tabular}\n% \\end{table}\n\n% \\end{frame}\n% % section current_res (end)\n% \\section{Conclusions-Future work} % (fold)\n% \\label{sec:conclusions_future_work}\n% \\subsection{Future work} % (fold)\n% \\label{sub:future_work}\n\n% % subsection future_work (end)\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{Future Work}\n% \\begin{itemize}\n%     \\item Contribution I: Discriminative Feature-oriented Dictionary Learning\\\\\n%     Extension to broader histopathological image classification problems.\n%     \\medskip\n\n%     \\item Proposed Contribution II: Subspace Decomposition Dictionary Learning\\\\\n%     \\begin{itemize}\n\n%     \\item Applying SDDL on more challenging datasets \n%     \\item Comparing with others DL methods\n%     \\end{itemize}\n%     \\medskip\n\n%     \\item Proposed Contribution III: \n%     \\begin{itemize}\n%         \\item Developing a new sparsity model and the corresponding dictionary learning framework. \n%     \\end{itemize}\n% \\end{itemize}\n% \\end{frame}\n\n% % ==================================New Slide============================================\n% \\subsection{Status and Roadmap} % (fold)\n% \\label{sub:status_and_roadmap}\n\n% % subsection status_and_roadmap (end)\n% \\begin{frame}\n% \\frametitle{Status and Roadmap}\n% \\begin{itemize}\n%     \\item Ph.D. candidacy exam: Jan 2014\n%     \\medskip\n%     \\item Ph.D. compressive exem: Dec 2015\n%     \\medskip\n%     \\item Contribution I: Discriminative Feature-oriented Dictionary Learning\n%     \\begin{itemize}\n%         \\item Conference paper published and presented; journal paper accepted.\n%     \\end{itemize}\n\n%     \\medskip\n%     \\item Contribution II: Subspace Decomposition Dictionary Learning\n%     \\begin{itemize}\n%         \\item Formulation of ideas, conference paper draft under preparation\n%     \\end{itemize}\n\n%     \\medskip\n%     \\item Contribution III: \n%     \\begin{itemize}\n%         \\item Formulation of ideas under preparation\n%     \\end{itemize}\n%     \\medskip\n%     \\item Expected date of graduation: Dec 2017.\n% \\end{itemize}\n\n% \\end{frame}\n\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\frametitle{List of Publications}\n% \\tcb{\\textbf{Refereed Journals:}}\n% \\begin{enumerate}\n%   \\item Tiep Vu, \\etal ``Histopathological Image Classification using Discriminative Feature-oriented Dictionary Learning''. Accepted to {\\bf IEEE Transactions on Medical Imaging}, 2015.\n% \\end{enumerate}\n% \\tcb{\\textbf{Refereed Conferences:}}\n% \\begin{enumerate}\n%  \\item Tiep Vu, \\etal ``DFDL:  Discriminative Feature-oriented Dictionary Learning for Histopathological Image Classification.'' In {\\bf IEEE International Symposium on Biomedical Imaging (ISBI)}, April 2015.\n%      \\item Tiep Vu \\etal, ``Subspace Decomposition Dictionary Learning for Object Classification'', under preparation, to be submitted to {\\bf IEEE International Conference on Image Processing (ICIP)}, 2016.\n% \\end{enumerate}\n% \\end{frame}\n% % section conclusions_future_work (end)\n% \\begin{frame}\n\n%   \\frametitle{}\n\n% \\begin{center}\n\n% \\Huge{\\tcb{Thank you!}}\\\\\n% \\large{\\tcb{Questions?}}\n% \\end{center}\n\n\n% \\end{frame}\n% % subsection complexity_analysis (end)\n% % \\input{Slides/contributionI}\n\n% %% ========= Back-up slides ==============================\n\n% % \\section{Backup slide} % (fold)\n% \\appendix\n% % \\label{sec:backup_slide}\n% \\begin{frame}\n\n%   \\frametitle{}\n\n% \\begin{center}\n\n% \\Large{\\tcb{Backup slides}}\n% \\begin{itemize}\n%     \\item FISTA\\footnoteFISTA~ algorithm (Slide \\ref{sli:fista}).\n%     \\item DFDL - update $\\bD$ (Slide \\ref{sli:dfdl_updateD}).\n\n%     \\item SDDL - update $\\bX$ (Slide \\ref{sddl_updateX}).\n%     % \\item SDDL - update $\\bX^0$\n\n%     % \\item SDDL - update $\\bD_j$\n\n%     \\item SDDL - update $\\bD_0$ (Slide \\ref{sli:sddl_updateD0}).\n% \\end{itemize}\n% \\end{center}\n% \\end{frame}\n\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\label{sli:fista}\n% \\frametitle{FISTA\\footnoteFISTA~ algorithm}\n% Solve the problem: $\\displaystyle\\bX = \\arg\\min_{\\bX} f(\\bX) + g(\\bX)$ with:\n% \\begin{itemize}\n%     \\item $g: \\R^{n\\times n} -\\leftarrow \\R:$ continuous, convex, possibly \\textit{nonsmooth.}\n%     \\item $f: \\R^{n\\times n} -\\leftarrow \\R:$ smooth convex function with continuously differentiable with Lipschitz continuous gradient $L(f).$\n% \\end{itemize}\n\n%     \\vspace{-.1in}\n% {\\small \\begin{algorithm}[H]\n%   \\begin{algorithmic}[0]\n%     \\STATE \\tb{INPUT:} {$L = L(f)$ - A Lipschitz constant of $\\nabla f$}. \n%     \\STATE \\textbf{Step 0}. Take $\\bY_1 = \\bX_0$, $t_1 = 1$\n%     \\STATE \\textbf{Step k.} ($k \\geq 1$), compute:\n%     \\vspace{-.1in}\n%       \\begin{eqnarray*}\n%             \\bX_k &=& \\arg\\min_{\\bX} \\left\\{g(\\bX) + \\frac{L}{2}\\norm{\\bX - \\left(\\bY_k - \\frac{1}{L}\\nabla f(\\bY_k)\\right)}_F^2\\right\\}          \\\\\n%             t_{k+1} &=& \\frac{1 + \\sqrt{1 + 4t_k^2}}{2},\\\\\n%             \\bY_{k+1} &=& \\bX_k + \\frac{t_k - 1}{t_{k+1}} (\\bX_k - \\bX_{k+1}).\n%       \\end{eqnarray*}\n%       \\STATE \\tb{RETURN:} $\\bX_k$\n%     \\end{algorithmic}\n%     % \\caption{DFDL}\n%     \\label{alg:seq}\n%   \\end{algorithm}}\n% \\end{frame}\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\label{sli:dfdl_updateD}\n% \\frametitle{DFDL - update $\\bD$}\n% \\begin{itemize}\n%     \\item With constraints $\\|\\bd_j\\|_2^2 = 1, j = 1, \\dots, k$: $\\trace(\\bD^{T}\\bD) = k$, then:\n%     \\begin{equation*}\n%         \\trace(\\bD(\\Fb - \\lambda_{\\min}(\\Fb)\\bI)\\bD^{T}) = \\trace(\\bD\\Fb\\bD^{T}) - \\lambda_{\\min}(\\Fb)k\n%     \\end{equation*}\n%     \\item If $\\Fb$ is symmetric, $\\Fb - \\lambda_{\\min}(\\Fb)$ is PSD.\n%     \\item Solution for: $\\displaystyle \\bD = \\arg\\min_{\\bD}\\trace(\\bD\\Fb\\bD^{T}) - 2\\trace(\\bD^{T}\\bD)$ with PSD $\\Fb$ is:\n%    \\begin{eqnarray*}\n%         \\bu_j &\\leftarrow &\\frac{1}{\\Fb(j,j)}(\\be - \\bD\\fb_j) + \\bd_j \\\\\n%         \\bd_j & \\leftarrow & \\frac{1}{\\max(\\norm{\\bu_j}, 1)}\\bu_j\n%   \\end{eqnarray*}\n% \\end{itemize}\n\n% \\end{frame}\n% % ==================================New Slide============================================\n% \\begin{frame}\n% \\label{sddl_updateX}\n% \\frametitle{SDDL - update $\\bX$}\n% %-------------------------------------------------------------------\n% %        Include graphic        \n% %-------------------------------------------------------------------    \n% \\begin{center}      \n%      \\includegraphics[width=\\textwidth]{pgfs/SDDL_solution2_backup.pdf};\n% \\end{center}\n\n\n% \\end{frame}\n\n% % ==================================New Slide============================================\n% \\def\\hateta{\\hat{\\eta}}\n% \\begin{frame}\n% \\label{sli:sddl_updateD0}\n% \\frametitle{SDDL - update $\\bD_0$}  \n% \\begin{equation*}\n%     \\bD_0 = \\arg\\min_{\\bD_0} \\|\\bL - \\bD_0\\bX^0\\|_F^2  + \\hateta\\|\\bD_0\\|_*\n% \\end{equation*}\n% Rewrite the problem as:\n% \\begin{eqnarray*}\n%     (\\bD_0, \\bJ) = \\arg\\min_{\\bD_0, \\bJ} \\|\\bL - \\bD_0\\bX^0\\|_F^2 + \\hateta\\|\\bJ\\|_* \\text{~~subject to:~~} \\bJ = \\bD_0\n% \\end{eqnarray*}\n% This problem could be solved by ADMM\\footnoteADMM~ as follows:\n% \\begin{eqnarray*}\n%     \\label{eqn:sddl_Dc_Dc}\n%   \\bDc^{k+1} &=& \\arg\\min_{\\bDc} \\|\\bL - \\bD_0\\bX^0\\|_F^2 + \\frac{\\rho}{2} \\|\\bJ^k - \\bDc + \\bU^k\\|_F^2 \\text{~~s.t.:~~} \\|\\bd_0^i\\|_2^2 \\leq 1, \\\\\n%     \\label{eqn:sddl_Dc_J}\n%   \\bJ^{k+1} &=& \\arg\\min_{\\bJ} \\frac{\\eta}{2}\\|\\bJ\\|_* + \\frac{\\rho}{2} \\|\\bJ - \\bDc^{k+1} + \\bU^k\\|_F^2, \\\\\n%   \\bU^{k+1} &=& \\bU^k + \\bJ^{k+1} - \\bDc^{k+1}.\n% \\end{eqnarray*}\n\n% \\end{frame}\n\n\\section{Part 2: LRSDL}\n\\label{sec:contribution_ii_sddl}\n\\begin{frame}\n  \\frametitle{}\n\\begin{center}\n\\large{\\tcb{Part II: \\\\LRSDL - Low-rank shared dictionary learning}}\n\\end{center}\n\\begin{enumerate}\n  \\item  Tiep Vu, Vishal Monga,``Learning a low-rank shared dictionary for object classification'', {\\bf IEEE International Conference on Image Processing (ICIP)}, 2016.\n  \\item  Tiep Vu, Vishal Monga, ``Fast low-rank shared dictionary for image classification'', Transactions on Image Processing, 2017.\n\\end{enumerate}\n\\end{frame}\n\\subsection{Main idea}\n\n\\begin{frame}\n\\frametitle{Recall Sparse Representation-based classification\\footnoteSRC}\n\\begin{figure}[h!]\n\\centering\n% \\includegraphics[width = 1\\textwidth]{pgfs/idea1_1.pdf}\n\\includegraphics[width = 1\\textwidth]{pgfs/idea1_32.pdf}\n\\caption{\\small  Ideal structure of the coefficient matrix in SRC.}\n\\vspace{-0.1in}\n\\end{figure}\nMost of dictionary learning methods have tried to encourage \\tcb{the code matrix $\\bX$ to be block diagonal}.\n\\end{frame}\n% ==================================New Slide============================================\n\\begin{frame}\n\\frametitle{Basic Idea}\n\\begin{figure}[h!]\n\\centering\n\\includegraphics[width = 0.8\\textwidth]{pgfs/idea1_22.pdf}\n\\end{figure}\n\\end{frame}\n% ==================================New Slide============================================\n% \\subsection{Problem formulation} % (fold)\n\\label{sub:problem_formu}\n% subsection problem_formu (end)\n\\begin{frame}\n\\frametitle{LRSDL - Idea visualization}\n% \\hspace{-0.1cm}\n\\includegraphics[width =1\\textwidth]{pgfs/idea_SDDL_2.pdf}\\\\\n% {\\small Without \\tcr{red terms}, SDDL becomes FDDL.}\n\\end{frame}\n% ==================================New Slide============================================\n\n% ==================================New Slide============================================\n\\subsection{Solution} % (fold)\n\\label{sub:solution}\n\n% subsection solution (end)\n\\begin{frame}\n\\frametitle{Solution to LRSDL} \n% \\hspace{-0.2cm}\n\n% Don't waste you time on adjusting, it's perfect now\n\\includegraphics[width =1\\textwidth]{pgfs/SDDL_solution2.pdf}\n\n\\end{frame}\n\n% =========================== New Slide =================================\n\\begin{frame}\n\\frametitle{Definition}\nGiven a block matrix $\\bA = [\\bA_{ij}]$, define a function $\\M(\\bA)$ which \ndoubles diagonal blocks of $\\bA$.\n{ \\begin{equation}\n    \\underbrace{\\bmt \n        \\bA_{11} &  \\dots & \\bA_{1C}\\\\\n        \\bA_{21} &  \\dots & \\bA_{2C}\\\\\n        \\dots    &  \\dots & \\dots\\\\\n        \\bA_{C1} &  \\dots & \\bA_{CC}\n        \\emt}_{\\bA}\n    \\mapsto \\underbrace{\\bA + \\bmt \n        \\bA_{11} & \\dots & \\bzeros\\\\\n        \\bzeros  & \\dots & \\bzeros\\\\\n        \\dots    & \\dots & \\dots\\\\\n        \\bzeros  & \\dots & \\bA_{CC}\n        \\emt}_{\\M(\\bA)}\n\\end{equation}}\nNote:\n\\begin{itemize}\n  \\item $\\M(\\bA)$ requires a low computational cost.\n\n  \\item $\\bA$ is not necessarily square but number of column blocks and number of row blocks must be the same.\n\\end{itemize}\n\\end{frame}\n% =========================== New Slide =================================\n\\begin{frame}\n\\frametitle{Efficient Algorithms for FDDL\\footnoteFDDL \\\\ Update $\\bD$}\nLet: $f_1(\\bY, \\bD, \\bX) = \\|\\bY - \\bD\\bX\\|_F^2 + \\sum_{c = 1}^C \n    \\left(\\|\\bY_c - \\bD_c \\bX_c^c\\|_F^2 + \n    \\sum_{i \\neq c} \\|\\bD_i \\bX^i_c\\|_F^2\\right)$\n% \\frametitle{Efficient Algorithms for FDDL}\n\n\\begin{tcolorbox}[colback=white!10,colframe=blue!55!black,title= Lemma 1: ]\n\\vspace{-0.2in}\n\\begin{eqnarray*}\n  \\bD &=& \\arg\\min_{\\bD} f_1(\\bY, \\bD, \\bX)\\\\\n   &=& \\arg\\min_{\\bD} -2\\trace(\\bE\\bD^T) + \\trace(\\Fb\\bD^T\\bD) \\\\\n    (\\text{s.t.~} &&\\|\\bd_j\\|_2 \\leq 1, \\forall j = 1, 2, \\dots, K.)\n\\end{eqnarray*}\nwhere $\\bE = \\bY\\M(\\bX)^T, ~\\Fb = \\M(\\bX\\bX^T)$.\n\\end{tcolorbox}\n\n(Compare to original ODL: $\\bE = \\bY\\bX^T, ~\\Fb = \\bX\\bX^T$)\n\n% \\pause\n$\\imply$ LRSDL dictionary update:\n% \\begin{equation}\n%   \\bD = \\arg\\min_{\\bD} -2\\trace(\\bE\\bD^T) + \\trace(\\Fb\\bD^T\\bD)\n% \\end{equation}\n% replace \n$$\\bE = (\\bY - \\bD_0\\bX^0)\\M(\\bX)^T, ~ \\Fb = \\M(\\bX\\bX^T).$$\n\\end{frame}\n\n% =========================== New Slide =================================\n\\begin{frame}\n\\frametitle{Efficient Algorithms for FDDL\\footnoteFDDL \\\\ Update $\\bX$}\nLet: $f_2(\\bX) = \\sum_{c=1}^C \\|\\bX_c - \\bM_c\\|_F^2 - \\|\\bM_c - \\bM\\|_F^2 + \n          \\|\\bX\\|_F^2.$\nThen:\n\\begin{equation}\n    \\bX = \\arg\\min_{\\bX} \\underbrace{\\frac{1}{2} f_1(\\bY, \\bD, \\bX) + \n    \\frac{\\lambda_2}{2} f_2(\\bX)}_{g(\\bX)} + \\lambda_1 \\|\\bX\\|_1 \n\\end{equation}\n$\\bX$ is solved using FISTA\\footnoteFISTA which requires gradient of $g(\\bX)$ at each iteration:\n\n\n\\begin{tcolorbox}[colback=white!10,colframe=blue!55!black,title= Lemma 2: ]\n\\vspace{-0.2in}\n\\begin{eqnarray}\n  \\frac{\\partial \\frac{1}{2}f_1}{\\partial\\bX} &=& \\M(\\bD^T\\bD)\\bX - \\M(\\bD^T\\bY)\\\\\n  \\label{eqn:grad_f2}\n  \\frac{\\partial \\frac{1}{2}f_2}{\\partial\\bX} &=& 2\\bX + \\bM \n     - 2\\underbrace{\\bmt \\bM_1 & \\bM_2 & \\dots & \\bM_C\\emt}_{\\widehat{\\bM}}.\n\\end{eqnarray}\n\\end{tcolorbox}\n\n\\end{frame}\n\n% =========================== New Slide =================================\n\\begin{frame}\n\\frametitle{Original and efficient FDDL convergence rate comparison}\n% Let $\\lbar{\\bX} = \\bmt \\bX \\\\ \\bX^0 \\emt.$ \n% \\begin{equation*}\n%     \\frac{\\partial \\lbar{g}}{\\partial \\lbar{\\bX}} = \n%     \\bmt  \\frac{\\partial \\lbar{g}}{\\partial \\bX} \\\\\n%         \\frac{\\partial \\lbar{g}}{\\partial \\bX^0}\\emt\n% \\end{equation*}\n% \\begin{equation*}\n%     =  \\bmt \\tcr{\\left(\\M(\\bD^T\\bD) + 2\\lambda_2\\bI \\right)}\\bX - \\tcr{\\M(\\bD^T\\bY)} + \n%       \\lambda_2(\\bM - 2\\widehat{\\bM}) - \\M(\\tcr{\\bD^T\\bD_0}\\bX^0)\\\\\n%     \\tcr{(2\\bD_0^T\\bD_0 + \\lambda_2\\bI)}\\bX^0 - \\tcr{2\\bD_0^T\\bY} + \n%       \\tcr{\\bD_0^T\\bD}\\M(\\bX) - \\lambda_2 \\bM^0\n%     \\emt \n% \\end{equation*}\n% \\end{equation}\n% \\tcr{red terms} are pre-calculated.\n\\includegraphics[width =1\\textwidth]{pgfs/compare_FDDL_LRSDL2.pdf}\n% \\capption{Convergence rate comparison} \n\n\\tcb{The E-FDDL produces a much lower cost function with a small amount of running time.}\n\\end{frame}\n% ==================================New Slide ===========================\n% \\begin{frame}\n% \\frametitle{Efficient algorithms for FDDL, performance validation} \n% \\vspace{-0.1in}\n% \\includegraphics[width =1\\textwidth]{pgfs/compare_FDDL_LRSDL.pdf}\n\n% \\end{frame}\n% =========================== New Slide =================================\n% \\begin{frame}\n% \\frametitle{Traditional algorithm for updating $\\bD$ in DLSI\\footnoteDLSI}\n% The cost function:\n% \\begin{equation}\n%     f(\\bD, \\bX) = \\sum_{c=1}^C\\left(\\|\\bY_c - \\bD_c \\bX_c\\|_F^2  + \\lambda\\|\\bX_c\\|_1 \\right)\n%             + \\eta \\sum_{i \\neq c} \\|\\bD_i^T \\bD_c\\|_F^2\n% \\end{equation}\n% Updating $\\bD_c$:\n% \\begin{eqnarray*}\n%   \\bD_c  =  \\arg\\min_{\\bD_c} \\|\\bY_c - \\bD_c \\bX_c\\|_F^2 + \\eta \\|\\bA\\bD_c\\|_F^2 \n%     \\text{~s.t.~~}  \\|\\bd_c^k\\|_2^2 \\leq 1.\n% \\end{eqnarray*}\n% Traditional approach: updating column by column of $\\bD_c$ by\n% \\begin{eqnarray}\n%   \\bu &=& \\tcr{\\left(\\|\\bX_c(k,:)\\|_2^2\\bI + \\eta \\bA^T\\bA\\right)^{-1}}\n%       (\\bY_c - \\sum_{i \\neq k} \\bd_c^i\\bX_c(i,:))\\bX_c(k,:)^T \\\\\n%   \\bd_c^k &=& \\frac{\\bu}{\\|\\bu\\|_2}\n% \\end{eqnarray}  \n% $\\imply$ very costly since \\tcr{each column requires a matrix inversion.}\n\n% \\end{frame}\n% % =========================== New Slide =================================\n% \\begin{frame}\n% \\frametitle{Efficient algorithm for updating $\\bD$ in DLSI\\footnoteDLSI}\n% By ignoring the class index, the problem of updating class-specific dictionaries is equivalent to:\n% \\begin{eqnarray*}\n%   (\\bD, \\bZ) &=& \\arg\\min_{\\bD, \\bZ} \\|\\bY - \\bD\\bX\\|_F^2 + \\eta \\|\\bA \\bZ\\|_F^2\\\\\n%   \\text{s.t.}&& \\|\\bd_k\\|_2^2 \\leq 1 \\\\\n%   && \\bD = \\bZ.\n% \\end{eqnarray*}\n% ADMM\\footnoteADMM update procedure:\n% Choose a $\\rho$, let $\\bZ, \\bU = \\bD$.\n% \\begin{eqnarray*}\n%   \\bD &=& \\arg\\min_{\\bD} -2\\trace((\\bY\\bX^T + \\rho/2 (\\bZ - \\bU))\\bD^T) \n%       +\\trace\\left((\\bX\\bX^T + \\rho/2 \\bI)\\bD^T\\bD\\right)\\\\\n%   \\bZ &=& \\tcr{(2\\lambda \\bA^T\\bA + \\rho \\bI)^{-1}}(\\bD + \\bU) \\\\\n%   \\bU &=& \\bU + \\bD + \\bZ \n% \\end{eqnarray*}\n% This new algorithm requires only one matrix inversion.\n% \\end{frame}\n% % ==================================New Slide ===========================\n% \\begin{frame}\n% \\frametitle{Efficient algorithms for DLSI, performance validation} \n% \\vspace{-0.1in}\n% \\includegraphics[width =1\\textwidth]{pgfs/compare_DLSI.pdf}\n\n% \\end{frame}\n% % ==================================New Slide ===========================\n% \\begin{frame}\n% \\frametitle{Efficient algorithms for DLCOPAR\\footnoteDLCORPA, performance validation} \n% \\vspace{-0.1in}\n% \\includegraphics[width =1\\textwidth]{pgfs/compare_DLCOPAR.pdf}\n\n% \\end{frame}\n% ==================================New Slide ===========================\n\n\\begin{frame}\n\\frametitle{Complexity analysis for different dictionary learning methods}\n\\begin{table}[t]\n% \\caption{Complexity analysis for different dictionary learning methods}\n    \\centering\n    % \\begin{tabular}{|l|l|c}\n    \\label{tab:complexity_analysis}\n    {\\small\n    \\begin{tabular}{|l|l|l|}\n    \\hline \n    Method & Complexity & \\begin{tabular}[c]{@{}c@{}} Plugging \\\\ numbers\\end{tabular}\\\\ \\hline \n    \\hline \n    O-DLSI & $Ck(kd + dn + qkn)+ Cqkd^3 $& $6.25\\times 10^{12}$\\\\% & $9.45 \\times 10^9$ \\\\\n    \\hline \n    E-DLSI & \\begin{tabular}[c]{@{}c@{}} $Ck(kd + dn + qkn) +$ \\\\ $Cd^3 + Cqdk(qk+d) $ \\end{tabular}& $3.75\\times 10^{10}$\\\\% & $10^8$ \\\\\n    \\hline \n    O-FDDL  & \\begin{tabular}[c]{@{}c@{}} $C^2dk(n+Ck+Cn) +$ \\\\ $+Ck^2q(d + C^2n)$ \\end{tabular}& $2.51\\times 10^{11}$\\\\% & $4.68 \\times 10^{10}$ \\\\ \\hline\n    \\hline \n    % \\hline \n    E-FDDL & $ C^2k((q+1)k(d + Cn) + 2dn)    $  & $1.29\\times 10^{11}$\\\\ %   & $2.52\\times 10^{10}$ \\\\\n    % \\hline \n    \\hline\n    O-COPAR & $C^3k^2(2d + Ck + qn) + Cqkd^3 $  & $6.55\\times 10^{12}$\\\\\n    \\hline \n    E-COPAR & \\begin{tabular}[c]{@{}c@{}}$C^3k^2(2d + Ck + qn)+$ \\\\ $+Cd^3 + Cqdk(qk+d)$\\\\ \\end{tabular}  & $3.38\\times 10^{11}$\\\\\n    \\hline\n    LRSDL & \\begin{tabular}[c]{@{}c@{}}$C^2k((q+1)k(d + Cn) + 2dn)$ \\\\ $C^2dkn + (q+q_2)dk^2 $ \\end{tabular} & $1.3\\times 10^{11}$\\\\\n    \\hline \n    \\end{tabular}\n    }\n\\end{table}\nNote: O- original algorithm, E- proposed efficient algorithm.\\\\\nLast column: $C = 100, n = 20, k = 10, q = q_2 = 50, d = 500$.\n\\end{frame}\n\n\n% =========================== New Slide =================================\n% \\begin{frame}\n% \\frametitle{DICTOL: the Dictionary Learning Toolbox}\n% \\begin{itemize}\n%   \\item Languages: MATLAB, Python\n%   \\item Methods: ODL, SRC, LCKSVD\\footnoteLCKSVD, DLSI\\footnoteDLSI, FDDL\\footnoteFDDL, DLCOPAR\\footnoteDLCORPA, $D^2L^2R^2$\\footnoteDLR, LRSDL and several\n%   supporting functions.\n%   \\item \\href{https://bitbucket.org/tiepvupsu/dictol/src}{\\beamergotobutton{Link}}\n% \\end{itemize}\n\n% \\end{frame}\n% =========================== New Slide =================================\n\\subsection{Experimental results} % (fold)\n\\label{sub:experimental_results}\n\n% subsection experimental_results (end)\n\\begin{frame}\n\\frametitle{}\n\\centering\n\\tcb{\\Huge Experimental results}\n\n\\end{frame}\n% =========================== New Slide =================================\n\\begin{frame}\n\\frametitle{Synthetic data}\n\\vspace{-0.1in}\n\\begin{itemize}\n\t\\item Four classes, each image is 20$\\times$20 pixel. For each class, 800 images for training, 200 images for test. \n\t\n\t\\item Images are generated as weighted sum of class-specific, shared elements, and noise.\n\t\n\\end{itemize}\n%\\includegraphics[width =1\\textwidth]{pgfs/visual_bases_synthetic3.pdf}\n\\includegraphics[width =1\\textwidth]{pgfs/visual_bases_synthetic_revised.pdf}\n\n\\end{frame}\n\n% =========================== New Slide =================================\n\\begin{frame}\n\\frametitle{Widely used datasets}\n% \\vspace{-0.1in}\n\\begin{figure}\n% \\includegraphics[width =.7\\textwidth]{pgfs/compare_shared.pdf}\n% \\caption{Classification accuracy as a function of the shared dictionary size.}\n\\includegraphics[width = 0.55\\textwidth]{pgfs/examples_landscape.pdf}\n\\caption{\\small Examples from five datasets. }\n\\end{figure}\n\\end{frame}\n% =========================== New Slide =================================\n\\begin{frame}\n\\frametitle{Overall Classification on well-known datasets}\n\\begin{table}[]\n\\centering\n\\caption{Results (\\%) on different databases.}\n\\label{my-label}\n{\\small \\begin{tabular}{|l||c|c|c|c|c|c|}\n\\hline\n        & \\begin{tabular}[c]{@{}c@{}}Ext. \\\\ YaleB\\end{tabular} & AR    & \\begin{tabular}[c]{@{}c@{}}AR \\\\ gender\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}Oxford \\\\ Flower\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}Caltech \\\\ 101\\end{tabular} & COIL100 \\\\ \\hline \\hline\nSRC\\footnoteSRC         & 97.96      & 97.33      & 92.57      & 75.79      & 72.15      &81.45\\\\ \\hline\nLC-KSVD1\\footnoteLCKSVD & 97.09      & 97.78      & 88.42      & 91.47      & 73.40      &81.37\\\\ \\hline\nLC-KSVD2 & 97.80      & 97.70      & 90.14      & 92.00      & 73.60      &81.42\\\\ \\hline\nDLSI\\footnoteDLSI       & 96.50      & 96.67      & 94.57      & 85.29      & 70.67      &80.67\\\\ \\hline\nFDDL\\footnoteFDDL       & 97.52      & 97.00      & 93.70      & 91.17      & 73.83      &77.45\\\\ \\hline\n$D^2L^2R^2$\\footnoteDLR & 98.03      & 95.33      & 93.71      & 83.23      & 75.26      &76.27\\\\ \\hline\nDLCOPAR\\footnoteDLCORPA & 98.19      & 98.50      & 95.14      & 85.29      & 76.05      &80.46\\\\ \\hline\n\\hline\nJDL\\footnoteJDL     & 97.73      & 98.80      & 92.83      & 80.29      & 75.90      &80.30\\\\ \\hline\n\\hline\nLRSDL                   & \\bf{98.76} & \\bf{98.83} & \\bf{95.42} & \\bf{92.58} & \\bf{76.70}  &\\textbf{84.65 }   \\\\ \\hline\n\\end{tabular}}\n\\end{table}\n\\end{frame}\n\n\n\n\n% =========================== New Slide =================================\n\\begin{frame}\n\\frametitle{Overall accuracy (\\%) as a function of number of training samples per class}\n\\includegraphics[width=\\textwidth]{pgfs/Compare_ntrain_TIP2016.pdf}\n\\end{frame}\n% ==================================New Slide ===========================\n\\section{DICTOL: A Dictionary Learning Toolbox} % (fold)\n\\label{sec:ATR_applications}\n\n% subsection experimental_results (end)\n\\begin{frame}\n\\frametitle{}\n\\centering\n\\tcb{\\Huge DICTOL: \\\\ A Dictionary Learning Toolbox}\n\n\\end{frame}\n\n% =========================== New Slide =================================\n\\subsection{Sonar images}\n\\vspace{-.2in}\n\\begin{frame}\n  \\frametitle{Sonar images\\footnoteJohn}\n  \\centering\n  \\includegraphics[width=\\textwidth]{pgfs/Sonar_slide.pdf}\n\n  % \\begin{enumerate}\n  %   \\item McKay, John, Vishal Monga, and Raghu Raj. ``Localized Dictionary design for Geometrically Robust Sonar ATR.'' arXiv preprint arXiv:1601.03323 (2016).\n  % \\end{enumerate}\n\\end{frame}\n% =========================== New Slide ================================= \n\\subsection{Hyperspectral images} % (fold)\n\\label{sub:hyperspectral_images}\n\n% subsection hyperspectral_images (end)\n\\begin{frame}\n  \\frametitle{Hyperspectral images$^{\\text{30}}$}\n  % \\begin{enumerate}\n  %   \\item Sun, Xiaoxia, Nasser M. Nasrabadi, and Trac D. Tran. ``Task-driven dictionary learning for hyperspectral image classification with structured sparsity constraints.'' \\textit{IEEE Transactions on Geoscience and Remote Sensing} 53.8 (2015): 4457-4471.\n  % \\end{enumerate}\n  \\centering\n  \\includegraphics[width=\\textwidth]{pgfs/TDDL_slide2.pdf}\n\\end{frame}\n% =========================== New Slide =================================\n\\begin{frame}\n\\frametitle{Conclusion}\n\\begin{itemize}\n  \\item Sparsity $\\rightarrow$ powerful prior for signal and image representation\n  \\medskip\n  \\item Class-specific dictionary design $\\rightarrow$ discriminative power of sparse representations.\n  \\medskip\n\n  \\item Benefits:\n  \\begin{itemize}\n    \\item Robustness to imaging distortions (because sparsity constrained optimization is a well-conditioned problem.)\n    \\item Graceful variation with training\n    \\item Multi-task multivariate scenarios $\\rightarrow$ heterogeneous sensor fusion\n  \\end{itemize}\n\n  \\medskip\n  \\item Can be applied to the recognition/classification problem in remotely sensed imagery (often highly corrupted by noises and occlusions). \n\n\\end{itemize}\n\n\n\n\\end{frame}\n\n\n\n% \\begin{frame}\n% \\frametitle{SDDL - Solving $\\bX$} \n% \\vspace{-0.1in}\n% \\includegraphics[width =1\\textwidth]{pgfs/SDDL_solution2.pdf}\n\n% \\end{frame}\n\n% % ==================================New Slide===========================\n\n% \\begin{frame}\n% \\frametitle{SDDL - Initialization}\n% The better initial guesses, the faster and more accurate the solution:\n% \\begin{itemize}\n%     \\item Initializing $\\bD_i$ and $\\bX_i^i$, $i = 1, 2, \\dots, C$:\n%     \\begin{equation*}\n%         (\\bD_i, \\bX_i^i) = \\arg\\min_{\\bD_i, \\bX_i^i} \\|\\bY_i - \\bD_i\\bX_i^i\\|_F^2 + \\lambda_1 \\|\\bX_i^i\\|_1 + \\lambda_2\\|\\bX_i^i - \\bM_i^i\\|_F^2.\n%     \\end{equation*}\n%     \\item Initializing $\\bD_0$ and $\\bX^0$:\n%     \\begin{equation*}\n%         (\\bD_0, \\bX^0) = \\arg\\min_{\\bD_0, \\bX_0} \\|\\bY - \\bD_0\\bX^0\\|_F^2 + \\lambda_1 \\|\\bX^0\\|_1 + \\lambda_2 \\|\\bX^0 - \\bM^0\\|_F^2 + \\eta \\|\\bD_0\\|_*.\n%     \\end{equation*}\n\n%     \\item $\\bX^j_i, j \\neq i$ are set to $\\mathbf{0}$.\n% \\end{itemize}\n% \\end{frame}\n% % ==================================New Slide===========================\n% \\begin{frame}\n% \\frametitle{SDDL - Classification scheme}\n% Given the class-specific dictionaries $\\bD_i$, the shared dictionary $\\bD^0$, and the mean vectors $ \\bm_1, \\dots, \\bm_C, \\bm^0$, for a new signal $\\by$:\n% \\begin{itemize}\n%     \\item The sparse code $(\\bx, \\bx^0)$ are found via:\n%     \\begin{equation*}\n%         \\boxed{(\\bx, \\bx^0) = \\arg\\min_{\\bx, \\bx^0} \\|\\by - \\bD_0\\bx^0 - \\bD\\bx\\|_2^2 + \\lambda_2\\|\\bx^0 - \\bm^0\\|_2^2 + \\lambda_1 \\norm{\\bmt \\bx \\\\ \\bx^0\\emt}_1}\n%     \\end{equation*}\n%     by FISTA\\footnoteFISTA.\n%     \\item Let $\\bar{\\by} = \\by - \\bD_0\\bx^0$, the identity of $\\by$ is determined as:\n%     \\begin{equation*}\n%         \\boxed{\\text{id}(\\by) = \\arg\\min_{1 \\leq i \\leq C} \\left(w\\|\\bar{\\by} - \\bD_i\\bx^i\\|_2^2 + (1-w)\\|\\bx - \\bm_i\\|_2^2 \\right)}\n%     \\end{equation*}\n%     where $w \\in (0, 1)$ is a preset weight to balance the contribution of the two terms.\n% \\end{itemize}\n% \\end{frame}\n\n    \n% % ==================================New Slide===========================\n% \\begin{frame}\n% \\frametitle{Applications to object classification in four datasets }\n% \\begin{center}\n  \n% \\includegraphics[width = .8\\textwidth]{pgfs/examples_4databases.pdf}\n% \\end{center}\n\n% \\end{frame}\n% % ==================================New Slide===========================\n\n% % ==================================New Slide===========================\n% \\begin{frame}\n% \\frametitle{Convergence rate comparison on the AR face database}\n% \\begin{figure}[t]\n% \\centering\n% \\includegraphics[width = 0.98\\textwidth]{pgfs/toy_cost.pdf}\n% \\caption{\\small LRSDL and FDDL convergence rate comparison. }\n% \\end{figure}\n% $d = 300, n_c = 7, C = 100, k_c = 7, k_0 = 0.$\n% \\end{frame}\n\n\n\n% \\begin{frame}\n% \\frametitle{Results}\n\n% \\begin{table}[]\n% \\centering\n% \\small\n% \\caption{Results (\\%) on widely used face databases.}\n% \\label{tab:face}\n% \\begin{tabular}{|l||c|c|c|c|}\n% \\hline\n% Data base       & \\multicolumn{2}{c|}{Extended YaleB} & \\multicolumn{2}{c|}{AR}        \\\\ \\hline\n% Training images                     & 15             & 30             & 15             & 20            \\\\ \\hline\n% \\hline\n% SRC\\footnoteSRC            & 92.84          & 95.13          & 95.18          & 96.83         \\\\ \\hline\n% LC-KSVD1\\footnoteLCKSVD    & 94.50          & 95.60          & 94.18          & 97.8          \\\\ \\hline\n% LC-KSVD2\\footnoteLCKSVD    & 95.00          & 96.00          & 94.45          & 97.70         \\\\ \\hline\n% FDDL\\footnoteFDDL          & 94.87          & 97.52          & 94.81          & 97.00         \\\\ \\hline\n% DLSI\\footnoteDLSI      & 90.88          & 96.50          & 90.45          & 96.67         \\\\ \\hline\n% DLCOPAR\\footnoteDLCORPA    & 94.57          & \\textbf{98.03} & 96.81          & 98.5          \\\\ \\hline\n% \\hline\n% LRSDL                           & \\textbf{95.25} & 98.00          & \\textbf{96.90} & \\textbf{98.7} \\\\ \\hline\n% \\end{tabular}\n% \\end{table}\n\n% % \\begin{table}[]\n% % \\centering\n% % \\caption{The recognition rates (\\%) of various methods on 4 popular databases}\n% % \\label{my-label}\n% % \\begin{tabular}{|l|c|c|c|c|}\n% % \\hline\n% % Method                  & AR Face    & Caltech101 & Fifteen Scene & Extended YaleB \\\\ \\hline\n\n% % SRC\\footnoteSRC         & 97.5       & 70.7       & 91.8          & 97.2           \\\\ \\hline\n% % LC-KSVD\\footnoteLCKSVD  & 97.8       & 73.6       & 92.9          & 96.7           \\\\ \\hline\n% % FDDL\\footnoteFDDL       & -          & -          & -             & 97.24          \\\\ \\hline\n% % LLC\\footnoteLLC         & 88.7       & 73.44      & 89.2          & -              \\\\ \\hline\n% % GDDL\\footnoteGDDL       & 96.7       & 73.6       & -             & 98.2           \\\\ \\hline\n% % DL-COPAR\\footnoteDLCORPA & -          & {\\bf 83.26}      & 85.37         & 98.3           \\\\ \\hline\n% % HSDDL                   & {\\bf -}    & -          & 79.24         & {\\bf 98.6}           \\\\ \\hline\n% % \\tcr{SDDL}                    & {\\bf 98.7} & 72.1       & {\\bf 93.95}   & 98.0           \\\\ \\hline\n% % \\end{tabular}\n% % \\end{table}\n\n% \\end{frame}\n\n% % ==================================New Slide===========================\n% \\begin{frame}\n% \\frametitle{Results on the Caltech 101 database.}\n% \\begin{table}[]\n% \\centering\n% \\small\n% \\caption{Results (\\%) on the Caltech 101 database.}\n% \\label{tab:caltech101}\n% \\begin{tabular}{|l||c|c||c|c|}\n% \\hline\n% % Database        & \\multicolumn{4}{c|}{Caltech 101}                                                                                                                                                                                            \\\\ \\hline\n% Training images & \\multicolumn{2}{c||}{15}                                                                      & \\multicolumn{2}{c|}{30 }                                                                      \\\\ \\hline\n%                 & \\begin{tabular}[c]{@{}c@{}}Acc. \\\\ (\\%)\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}Dict. \\\\ size\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}Acc. \\\\  (\\%)\\end{tabular} & \\begin{tabular}[c]{@{}c@{}}Dict. \\\\ size\\end{tabular} \\\\ \\hline\n%          \\hline\n% SRC\\footnoteSRC          & 64.26             & 1530         & 73.12              & 3060              \\\\ \\hline\n% LC-KSVD1\\footnoteLCKSVD    & 66.70             & 1530         & 73.40              & 2550              \\\\ \\hline\n% LC-KSVD2\\footnoteLCKSVD    & 67.70             & 1530         & 73.60              & 2550              \\\\ \\hline\n% FDDL\\footnoteFDDL             & 65.56             & 1530         & 73.64              & 2550              \\\\ \\hline\n% LLC\\footnoteLLC          & 65.43             & -            & 73.44              & -                 \\\\ \\hline\n% DLSI\\footnoteDLSI & 61.28             & 1530         & 70.72              & 2550              \\\\ \\hline\n% DLCOPAR\\footnoteDLCORPA    & 67.98             & 1120         & 75.27              & 2090              \\\\ \\hline\n% \\hline\n% LRSDL                           & \\textbf{68.76}    & 1120         & \\textbf{76.50}     & 2090              \\\\ \\hline\n% \\end{tabular}\n% \\end{table}\n% \\end{frame}\n% % section current_res (end)\n% % \\section{Conclusions-Future work} % (fold)\n% % \\label{sec:conclusions_future_work}\n% % \\subsection{Future work} % (fold)\n% % \\label{sub:future_work}\n\n% % subsection future_work (end)\n% % % ==================================New Slide===========================\n% % \\begin{frame}\n% % \\frametitle{Fuzzy Dictionary Learning (FuzzyDL)}\n% % \\begin{center}\n  \n% % \\includegraphics[width = \\textwidth]{pgfs/idea_FuzzyDL_Mar24.pdf}\n% % \\end{center}\n% % \\end{frame}\n% % % ==================================New Slide===========================\n% % % ==================================New Slide===========================\n% % \\begin{frame}\n% % \\frametitle{Fuzzy Dictionary Learning (FuzzyDL)}\n% % To 'mesure' the contribution of each class:\n% % \\begin{center}\n% %       \\begin{itemize}\n% %           \\item In classical SRC and related DLs:\\\\\n% %           \\begin{eqnarray*}\n% %             \\by &=& \\bD\\bx = \\bD_1\\bx^1 + \\bD_2 \\bx^2 + \\dots + \\bD_C\\bx^C, \\\\\n% %             &=& \\bD \\diag(\\bw_1) \\bx + \\bD \\diag(\\bw_2) \\bx + \\dots + \\bD \\diag(\\bw_C) \\bx,\\\\ \n% %             &=& \\bD \\bW_1 \\bx + \\bD \\bW_2 \\bx + \\dots + \\bD \\bW_C \\bx,\n% %           \\end{eqnarray*}\n% %           where elements of $\\bw_c$ are '1' at part of $\\bx$ corresponding with class $c$, '0' otherwise. \n% %         \\item $\\imply$ FuzzyDL is a more general framework with classification rule:\n% %         \\begin{equation}\n% %             \\text{id}(\\by) = \\min_{1 \\leq c \\leq C} \\|\\by - \\bD \\bW_c \\bx\\|_2.\n% %         \\end{equation}\n% %         \\item If $\\by$ belongs to class $c$, then: \n% %         \\begin{equation}\n% %             \\|\\by - \\bD\\bW_c\\bx\\|_2 \\text{~small,~} \\|\\bD\\bW_i\\bx\\|_2 \\text{~small,~} \\forall i \\neq c.\n% %         \\end{equation}\n% %       \\end{itemize}\n% % \\end{center}\n% % \\end{frame}\n\n% % % ==================================New Slide===========================\n% % \\begin{frame}\n% % \\frametitle{FuzzyDL optimization problem}\n% %     \\begin{eqnarray*}\n% %     \\tiny\n% % \\nonumber\n% %     (\\bD, \\bX, \\bW) &=& \\arg\\min_{\\bD, \\bX, \\bW} \\frac{1}{2} \\|\\bY - \\bD\\bX\\|_F^2 + \\\\ \n% %     &&\\frac{1}{2}\\sum_{c = 1}^{C} \\left( \\tcr{\\|\\bY_c - \\bD\\bW_c\\bX_c\\|_F^2 + \\sum_{i\\neq c} \\|\\bD\\bW_i\\bX_c\\|_F^2}\\right) + \\lambda_1\\|\\bX\\|_1  \\\\\n% %     && + \\lambda_2 \\left(\\sum_{c=1}^{C} \\left(\\|\\bX_c - \\bM_c\\|_F^2 - \\|\\bM_c - \\bM\\|_F^2\\right) + \\|\\bX\\|_F^2\\right)\\\\\n% %     \\text{subject to:}&& \\|\\bd_i\\|_2^2 \\leq 1\\\\\n% %     && \\tcr{ \\sum_{c=1}^C \\bw_i = \\bmt 1 & 1 & \\dots & 1\\emt^T}\\\\\n% %     && \\tcr{ \\bW \\succeq 0}.\n% % \\end{eqnarray*}\n% % \\begin{itemize}\n% %     \\item Solving each of $\\bX, \\bD, \\bW$ while others fixed. \n\n% %     \\item Solving each problem is nontrivial. \n% % \\end{itemize}\n% % \\end{frame}\n\n% % % ==================================New Slide===========================\n% % \\begin{frame}\n% % \\frametitle{Solving $\\bX$}\n% % \\begin{itemize}\n% %     \\item Similar to the method proposed in my LRSDL paper with gradient:\n\n% % \\begin{eqnarray*}\n% %     \\frac{\\partial J}{\\partial \\bX} &=& \\big(\\tcr{\\bD^T\\bD + (\\bD^T\\bD) \\circ (\\bW\\bW^T) + 4\\lambda_2\\bI}\\big)\\bX - \\tcr{\\bD^T\\bY}\\\\ && - \\tcr{\\bmt \\bD_1^T\\bY_1 & \\dots & \\bD_C^T\\bY_C\\emt} + 2\\lambda_2(\\bM - 2\\bmt \\bM_1 & \\dots & \\bM_C\\emt )\n% % \\end{eqnarray*}\n% %     where \\tcr{red terms} are independent on $\\bX$ and:\n% %     \\begin{equation}\n% %         \\bD_c = \\bD\\bW_c.\n% %     \\end{equation}\n\n% % \\end{itemize}\n% % ($\\circ$ is the element-wise product.)\n% % \\end{frame}\n\n% % % ==================================New Slide===========================\n% % \\begin{frame}\n% % \\frametitle{Solving $\\bD$}\n% %     \\begin{eqnarray*}\n% %         \\bD &=& \\arg\\min_{\\bD} \\|\\bY - \\bD\\bX\\|_F^2 + \\sum_{c=1}^C \\left(\\|\\bY_c - \\bD\\bW_c{\\bX}_c\\|_F^2 + \\sum_{i\\neq c} \\|\\bD\\bW_c\\bX_i\\|_F^2\\right) \\\\\n% %         &=& \\tcr{\\arg\\min_{\\bD} \\{-2\\text{trace}(\\bE\\bD^T) + \\text{trace}(\\Fb\\bD^T\\bD) \\}}\n% %     \\end{eqnarray*}\n% %     which can be solved by Online Dictionary Learning method with:\n% %     \\begin{eqnarray*}\n% %         \\bE &=& \\bY\\bX^T + \\sum_{c=1}^C \\bY_c (\\bW_c\\bX_c)^T \\\\\\\n% %         \\Fb &=& \\bX\\bX^T + (\\bX\\bX^T) \\circ (\\bW\\bW^T)\n% %     \\end{eqnarray*}\n% %     This method can also be applied to previous DL problems (instead of solving $\\bD_c$ one by one).\n% % \\end{frame}\n\n% % % ==================================New Slide===========================\n% % \\begin{frame}\n% % \\frametitle{Solving $\\bW$ (most difficult)}\n% % \\begin{itemize}\n% %     \\item After some (reliable) calculations:\n% %     % \\boxed{\n% %     \\begin{eqnarray*}\n% %         \\bw &=& \\arg\\min_{\\bw} \\frac{1}{2} \\sum_{c=1}^C (\\bw_c^T\\bH\\bw_c + \\bp_c^T\\bw_c) \\\\\n% %         \\text{s.t.}&& \\sum_{c=1}^C{\\bw_c} = \\bmt 1, 1, \\dots, 1 \\emt^T \\text{~and~} \\bw \\succeq 0.\n% %     \\end{eqnarray*}\n\n% %     \\item Equivalent \\tcb{Large-Scale} Nonnegative QP problem:\n% %     \\begin{eqnarray*}\n% %         \\boxed{\\bw = \\arg\\min_{\\bw} \\frac{1}{2} \\bw^T\\bQ\\bw + \\bp^T\\bw         \\text{~~s.t.~~} \\bA\\bw = \\bb \\text{~and~} \\bw \\succeq 0.}\n% %     \\end{eqnarray*}   \n\n% %     where: $\\bQ = \\bmt \n% %     \\bH & \\mathbf{0} & \\dots & \\mathbf{0}\\\\\n% %     \\mathbf{0} & \\bH & \\dots & \\mathbf{0} \\\\\n% %     \\vdots & \\vdots & \\vdots & \\vdots\\\\\n% %     \\mathbf{0} & \\mathbf{0} & \\dots & \\bH \\emt   , ~~ \\bp = \\bmt \\bp_1 \\\\ \\bp_2\\\\ \\vdots \\\\ \\bp_C\\emt, \\bA = \\bmt \\bI & \\bI & \\dots \\bI\\emt, \\bb = \\bmt 1 \\\\ 1 \\\\\\vdots \\\\ 1\\emt$\n% %     % }\n% % \\end{itemize}\n\n% % \\end{frame}\n\n% % % ==================================New Slide===========================\n% % \\begin{frame}\n% % \\frametitle{ADMM procedure to solve a NNQP with linear equality constraint.}\n% %  \\begin{eqnarray*}\n% %         \\boxed{\\bw = \\arg\\min_{\\bw} \\frac{1}{2} \\bw^T\\bQ\\bw + \\bp^T\\bw         \\text{~~s.t.~~} \\bA\\bw = \\bb \\text{~and~} \\bw \\succeq 0.}\n% %     \\end{eqnarray*}   \n% %     ADMM procedure with two auxiliary variables $\\bz, \\bu$:\n% %     \\begin{enumerate}\n% %         \\item Update $\\bw$: \n% %         \\begin{equation}\n% %             \\tcr{\\bmt \\bw \\\\ {\\nu}\\emt = \\bmt \\bQ/\\rho + \\bI & \\bA^T/\\rho \\\\ \\bA & \\mathbf{0} \\emt^{-1} \\bmt (\\bz - \\bu) - \\bp/\\rho \\\\ \\bb \\emt}\n% %         \\end{equation}\n% %         \\item Update $\\bz$:\n% %         \\begin{equation}\n% %             \\bz = \\max\\{\\mathbf{0}, \\bw + \\bu\\}.\n% %         \\end{equation}\n% %         \\item Update $\\bu$:\n% %         \\begin{equation}\n% %             \\bu = \\bu + \\bw - \\bz\n% %         \\end{equation}\n% %     \\end{enumerate}\n% %     \\tcr{Inverse of a Huge matrix,} but no worries... \n% % \\end{frame}\n\n% % % ==================================New Slide===========================\n% % \\begin{frame}\n% % \\frametitle{Contribution: a much simpler $\\bw$ update}\n\n% % \\begin{equation*}\n% %    \\bmt \\bQ/\\rho + \\bI & \\bA^T/\\rho \\\\ \\bA & \\mathbf{0} \\emt^{-1}\\bmt \\bv \\\\ \\bb\\emt  =\n% %     \\bmt \\text{vec}(\\lbH\\bV) - \\text{repmat} (\\text{mean}(\\lbH \\bV, 2) + \\bb/C, C, 1) \\\\ \\rho \\text{mean}(\\bV) - \\frac{\\rho}{C} \\hat{\\bH}\\bb\\emt.\n% % \\end{equation*}\n% % with:\n% % \\begin{eqnarray*}\n% %     \\hat{\\bH} &=& \\bH/\\rho + \\bI \\\\\n% %     \\lbH &=& \\hat{\\bH}^{-1}\\\\\n% %     \\bV &=& \\text{reshape}(\\bv, K, C)\n% % \\end{eqnarray*}\n% % \\end{frame}\n% % % ==================================New Slide===========================\n% % \\begin{frame}\n% % \\frametitle{Preliminary results on Fifteen Scene database}\n% %     \\includegraphics[width = 0.6\\textwidth]{figs/aa.png} The Fuzzy matrix $\\bW$ \\\\\n% %     \\includegraphics[width = 0.6\\textwidth]{figs/bb.png} The 'variability' of each class.\n% % \\end{frame}\n\n\n        \n% % %% =========  ==============================\n\n% % \\begin{frame}\n% % \\frametitle{Future Work}\n% % \\begin{itemize}\n    \n% %     \\item Implement/develope the new idea. \n% %     \\item Apply FuzzyDL to different challenging databases. \n% %     \\item Compare results on different set of training samples.\n% % \\end{itemize}\n% % \\end{frame}\n\n% % % ==================================New Slide===========================\n% % % \\subsection{Status and Roadmap} % (fold)\n% % \\label{sub:status_and_roadmap}\n\n% % % % subsection status_and_roadmap (end)\n% % % \\begin{frame}\n% % % \\frametitle{Status and Roadmap}\n% % % \\begin{itemize}\n% % %     \\item Ph.D. candidacy exam: Jan 2014\n% % %     \\medskip\n% % %     \\item Ph.D. comprehensive exam: Dec 2015\n% % %     \\medskip\n% % %     \\item Contribution I: Discriminative Feature-oriented Dictionary Learning\n% % %     \\begin{itemize}\n% % %         \\item Conference paper published and presented; journal paper accepted.\n% % %     \\end{itemize}\n\n% % %     \\medskip\n% % %     \\item Contribution II: Subspace Decomposition Dictionary Learning\n% % %     \\begin{itemize}\n% % %         \\item Formulation of ideas, conference paper draft under preparation.\n% % %     \\end{itemize}\n\n% % %     \\medskip\n% % %     \\item Contribution III: \n% % %     \\begin{itemize}\n% % %         \\item Formulation of ideas under preparation.\n% % %     \\end{itemize}\n% % %     \\medskip\n% % %     \\item Expected date of graduation: Dec 2017.\n% % % \\end{itemize}\n\n% % % \\end{frame}\n\n% % % % ==================================New Slide===========================\n% % % \\begin{frame}\n% % % \\frametitle{List of Publications}\n% % % \\tcb{\\textbf{Refereed Journals:}}\n% % % \\begin{enumerate}\n% % %   \\item Tiep Vu, \\etal ``Histopathological Image Classification using Discriminative Feature-oriented Dictionary Learning''. Accepted to {\\bf IEEE Transactions on Medical Imaging}, 2015.\n% % % \\end{enumerate}\n% % % \\tcb{\\textbf{Refereed Conferences:}}\n% % % \\begin{enumerate}\n% % %  \\item Tiep Vu, \\etal ``DFDL:  Discriminative Feature-oriented Dictionary Learning for Histopathological Image Classification.'' In {\\bf IEEE International Symposium on Biomedical Imaging (ISBI)}, April 2015.\n% % %      \\item Tiep Vu \\etal, ``Subspace Decomposition Dictionary Learning for Object Classification'', under preparation, to be submitted to {\\bf IEEE International Conference on Image Processing (ICIP)}, 2016.\n% % % \\end{enumerate}\n% % % \\end{frame}\n% % % % section conclusions_future_work (end)\n% % \\begin{frame}\n\n% %   \\frametitle{}\n\n% % \\begin{center}\n\n% % \\Huge{\\tcb{Thank you!}}\\\\\n% % \\large{\\tcb{Questions?}}\n% % \\end{center}\n\n\n% % \\end{frame}\n% % % subsection complexity_analysis (end)\n% % % \\input{Slides/contributionI}\n\n% % %% ========= Back-up slides ==============================\n\n% % % \\section{Backup slide} % (fold)\n% % % \\appendix\n% % % % \\label{sec:backup_slide}\n% % % \\begin{frame}\n\n% % %   \\frametitle{}\n\n% % % \\begin{center}\n\n% % % \\Large{\\tcb{Backup slides}}\n% % % \\begin{itemize}\n% % %     \\item FISTA\\footnoteFISTA~ algorithm (Slide \\ref{sli:fista}).\n% % %     \\item DFDL - update $\\bD$ (Slide \\ref{sli:dfdl_updateD}).\n\n% % %     \\item SDDL - update $\\bX$ (Slide \\ref{sddl_updateX}).\n% % %     % \\item SDDL - update $\\bX^0$\n\n% % %     % \\item SDDL - update $\\bD_j$\n\n% % %     \\item SDDL - update $\\bD_0$ (Slide \\ref{sli:sddl_updateD0}).\n% % % \\end{itemize}\n% % % \\end{center}\n% % % \\end{frame}\n\n% % % % ==================================New Slide===========================\n% % % \\begin{frame}\n% % % \\label{sli:fista}\n% % % \\frametitle{FISTA\\footnoteFISTA~ algorithm}\n% % % Solve the problem: $\\displaystyle\\bX = \\arg\\min_{\\bX} f(\\bX) + g(\\bX)$ with:\n% % % \\begin{itemize}\n% % %     \\item $g: \\R^{n\\times n} -\\leftarrow \\R:$ continuous, convex, possibly \\textit{nonsmooth.}\n% % %     \\item $f: \\R^{n\\times n} -\\leftarrow \\R:$ smooth convex function with continuously differentiable with Lipschitz continuous gradient $L(f).$\n% % % \\end{itemize}\n\n% % %     \\vspace{-.1in}\n% % % {\\small \\begin{algorithm}[H]\n% % %   \\begin{algorithmic}[0]\n% % %     \\STATE \\tb{INPUT:} {$L = L(f)$ - A Lipschitz constant of $\\nabla f$}. \n% % %     \\STATE \\textbf{Step 0}. Take $\\bY_1 = \\bX_0$, $t_1 = 1$\n% % %     \\STATE \\textbf{Step k.} ($k \\geq 1$), compute:\n% % %     \\vspace{-.1in}\n% % %       \\begin{eqnarray*}\n% % %             \\bX_k &=& \\arg\\min_{\\bX} \\left\\{g(\\bX) + \\frac{L}{2}\\norm{\\bX - \\left(\\bY_k - \\frac{1}{L}\\nabla f(\\bY_k)\\right)}_F^2\\right\\}          \\\\\n% % %             t_{k+1} &=& \\frac{1 + \\sqrt{1 + 4t_k^2}}{2},\\\\\n% % %             \\bY_{k+1} &=& \\bX_k + \\frac{t_k - 1}{t_{k+1}} (\\bX_k - \\bX_{k+1}).\n% % %       \\end{eqnarray*}\n% % %       \\STATE \\tb{RETURN:} $\\bX_k$\n% % %     \\end{algorithmic}\n% % %     % \\caption{DFDL}\n% % %     \\label{alg:seq}\n% % %   \\end{algorithm}}\n% % % \\end{frame}\n% % % % ==================================New Slide===========================\n% % % \\begin{frame}\n% % % \\label{sli:dfdl_updateD}\n% % % \\frametitle{DFDL - update $\\bD$}\n% % % \\begin{itemize}\n% % %     \\item With constraints $\\|\\bd_j\\|_2^2 = 1, j = 1, \\dots, k$: $\\trace(\\bD^{T}\\bD) = k$, then:\n% % %     \\begin{equation*}\n% % %         \\trace(\\bD(\\Fb - \\lambda_{\\min}(\\Fb)\\bI)\\bD^{T}) = \\trace(\\bD\\Fb\\bD^{T}) - \\lambda_{\\min}(\\Fb)k\n% % %     \\end{equation*}\n% % %     \\item If $\\Fb$ is symmetric, $\\Fb - \\lambda_{\\min}(\\Fb)$ is PSD.\n% % %     \\item Solution for: $\\displaystyle \\bD = \\arg\\min_{\\bD}\\trace(\\bD\\Fb\\bD^{T}) - 2\\trace(\\bD^{T}\\bD)$ with PSD $\\Fb$ is:\n% % %    \\begin{eqnarray*}\n% % %         \\bu_j &\\leftarrow &\\frac{1}{\\Fb(j,j)}(\\be - \\bD\\fb_j) + \\bd_j \\\\\n% % %         \\bd_j & \\leftarrow & \\frac{1}{\\max(\\norm{\\bu_j}, 1)}\\bu_j\n% % %   \\end{eqnarray*}\n% % % \\end{itemize}\n\n% % % \\end{frame}\n% % % % ==================================New Slide===========================\n% % % \\begin{frame}\n% % % \\label{sddl_updateX}\n% % % \\frametitle{SDDL - update $\\bX$}\n% % % %-------------------------------------------------------------------\n% % % %        Include graphic        \n% % % %-------------------------------------------------------------------    \n% % % \\begin{center}      \n% % %      \\includegraphics[width=\\textwidth]{pgfs/SDDL_solution2_backup.pdf};\n% % % \\end{center}\n\n\n% % % \\end{frame}\n\n% % % % ==================================New Slide===========================\n% % % \\def\\hateta{\\hat{\\eta}}\n% % % \\begin{frame}\n% % % \\label{sli:sddl_updateD0}\n% % % \\frametitle{SDDL - update $\\bD_0$}  \n% % % \\begin{equation*}\n% % %     \\bD_0 = \\arg\\min_{\\bD_0} \\|\\bL - \\bD_0\\bX^0\\|_F^2  + \\hateta\\|\\bD_0\\|_*\n% % % \\end{equation*}\n% % % Rewrite the problem as:\n% % % \\begin{eqnarray*}\n% % %     (\\bD_0, \\bJ) = \\arg\\min_{\\bD_0, \\bJ} \\|\\bL - \\bD_0\\bX^0\\|_F^2 + \\hateta\\|\\bJ\\|_* \\text{~~subject to:~~} \\bJ = \\bD_0\n% % % \\end{eqnarray*}\n% % % This problem could be solved by ADMM\\footnoteADMM~ as follows:\n% % % \\begin{eqnarray*}\n% % %     \\label{eqn:sddl_Dc_Dc}\n% % %   \\bDc^{k+1} &=& \\arg\\min_{\\bDc} \\|\\bL - \\bD_0\\bX^0\\|_F^2 + \\frac{\\rho}{2} \\|\\bJ^k - \\bDc + \\bU^k\\|_F^2 \\text{~~s.t.:~~} \\|\\bd_0^i\\|_2^2 \\leq 1, \\\\\n% % %     \\label{eqn:sddl_Dc_J}\n% % %   \\bJ^{k+1} &=& \\arg\\min_{\\bJ} \\frac{\\eta}{2}\\|\\bJ\\|_* + \\frac{\\rho}{2} \\|\\bJ - \\bDc^{k+1} + \\bU^k\\|_F^2, \\\\\n% % %   \\bU^{k+1} &=& \\bU^k + \\bJ^{k+1} - \\bDc^{k+1}.\n% % % \\end{eqnarray*}\n\n% % % \\end{frame}\n\n% % % section backup_slide (end)\n% \\end{document}\n% section backup_slide (end)\n\\end{document}",
			"file": "/Users/tiepvu/PROJECTS/02_LRSDL/LRSDL_paper/GroupMeeting_visitor_170913.tex",
			"file_size": 85211,
			"file_write_time": 131498070790000000,
			"settings":
			{
				"buffer_size": 83131,
				"line_ending": "Windows"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
		[
			[
				[
					"Anaconda Python Builder",
					""
				],
				[
					"Packages/Python/Python.sublime-build",
					""
				],
				[
					"Packages/Python/Python.sublime-build",
					"Syntax Check"
				],
				[
					"Packages/User/python2710.sublime-build",
					""
				]
			],
			[
				"Anaconda Python Builder",
				""
			]
		],
		[
			[
				[
					"Packages/LaTeXBox/support/LaTeX.sublime-build",
					""
				],
				[
					"Packages/LaTeXBox/support/LaTeX.sublime-build",
					"Force"
				]
			],
			[
				"Packages/LaTeXBox/support/LaTeX.sublime-build",
				"Force"
			]
		],
		[
			[
				[
					"Packages/LaTeXBox/support/LaTeX.sublime-build",
					""
				],
				[
					"Packages/LaTeXBox/support/LaTeX.sublime-build",
					"Force"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					""
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Traditional"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"PdfLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"XeLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"LuaLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder - PdfLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder - XeLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder - LuaLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Script Builder"
				],
				[
					"Packages/User/LaTeX.sublime-build",
					""
				]
			],
			[
				"Packages/LaTeXTools/LaTeX.sublime-build",
				"Traditional"
			]
		],
		[
			[
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					""
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Traditional"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"PdfLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"XeLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"LuaLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder - PdfLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder - XeLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder - LuaLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Script Builder"
				]
			],
			[
				"Packages/LaTeXTools/LaTeX.sublime-build",
				""
			]
		],
		[
			[
				[
					"Packages/LaTeXing/LaTeX.sublime-build",
					""
				],
				[
					"Packages/LaTeXing/LaTeX.sublime-build",
					"Clean up Files"
				],
				[
					"Packages/LaTeXBox/support/LaTeX.sublime-build",
					""
				],
				[
					"Packages/LaTeXBox/support/LaTeX.sublime-build",
					"Force"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					""
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Traditional"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"PdfLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"XeLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"LuaLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder - PdfLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder - XeLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Basic Builder - LuaLaTeX"
				],
				[
					"Packages/LaTeXTools/LaTeX.sublime-build",
					"Script Builder"
				],
				[
					"Packages/User/LaTeX.sublime-build",
					""
				]
			],
			[
				"Packages/LaTeXTools/LaTeX.sublime-build",
				"Traditional"
			]
		],
		[
			[
				[
					"Packages/Python/Python.sublime-build",
					""
				],
				[
					"Packages/Python/Python.sublime-build",
					"Syntax Check"
				]
			],
			[
				"Packages/Python/Python.sublime-build",
				""
			]
		],
		[
			[
				[
					"Packages/Python/Python.sublime-build",
					""
				],
				[
					"Packages/Python/Python.sublime-build",
					"Syntax Check"
				],
				[
					"Packages/User/python2710.sublime-build",
					""
				]
			],
			[
				"Packages/User/python2710.sublime-build",
				""
			]
		]
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 392.0,
		"last_filter": "re",
		"selected_items":
		[
			[
				"re",
				"File: Rename"
			],
			[
				"tog",
				"Python Breakpoints: Toggle"
			],
			[
				"move",
				"File: Move"
			],
			[
				"br",
				"Python Breakpoints: Toggle"
			],
			[
				"synpyt",
				"Set Syntax: Python"
			],
			[
				"copy",
				"File: Copy Path"
			],
			[
				"cop",
				"File: Copy Name"
			],
			[
				"ali",
				"AlignTab"
			],
			[
				"syntaxlate",
				"Set Syntax: LaTeX"
			],
			[
				"de",
				"File: Delete"
			],
			[
				"al",
				"AlignTab"
			],
			[
				"ren",
				"File: Rename"
			],
			[
				"alig",
				"AlignTab"
			],
			[
				"python",
				"Python Breakpoints: Toggle"
			],
			[
				"mov",
				"File: Move"
			],
			[
				"ins",
				"Package Control: Install Package"
			],
			[
				"synlig",
				"Set Syntax: Markdown Light"
			],
			[
				"rena",
				"File: Rename"
			],
			[
				"toc",
				"MarkdownTOC:Insert TOC"
			],
			[
				"syntalig",
				"Set Syntax: Markdown Light"
			],
			[
				"nam",
				"File: Copy Name"
			],
			[
				"in",
				"Package Control: Install Package"
			],
			[
				"inst",
				"Package Control: Install Package"
			],
			[
				"jum",
				"LaTeXTools: Jump to PDF"
			],
			[
				"setpy",
				"Set Syntax: Python"
			],
			[
				"remo",
				"Package Control: Remove Package"
			],
			[
				"rem",
				"Package Control: Remove Package"
			],
			[
				"r",
				"File: Rename"
			],
			[
				"dele",
				"File: Delete"
			],
			[
				"syntapy",
				"Set Syntax: Python"
			],
			[
				"synta",
				"Set Syntax: Markdown"
			],
			[
				"ty",
				"Markdown: Open with Typora.app"
			],
			[
				"syntax",
				"Set Syntax: Markdown"
			],
			[
				"typo",
				"Markdown: Open with Typora.app"
			],
			[
				"rene",
				"File: Rename"
			],
			[
				"origa",
				"Origami: Create Pane Below"
			],
			[
				"ma",
				"Markdown: Open with Typora.app"
			],
			[
				"install ",
				"Package Control: Install Package"
			],
			[
				"latex",
				"Set Syntax: LaTeX"
			],
			[
				"diff",
				"Diffy Compare"
			],
			[
				"dif",
				"Set Syntax: Diff"
			],
			[
				"remov",
				"Package Control: Remove Package"
			],
			[
				"del",
				"File: Delete"
			],
			[
				"insta",
				"Package Control: Install Package"
			],
			[
				"remove",
				"Package Control: Remove Package"
			],
			[
				"extract",
				"Extract Sublime Package: Extract all packages"
			],
			[
				"extra",
				"Extract Sublime Package: Extract all packages"
			],
			[
				"breakpoi",
				"Python Breakpoints: Toggle"
			],
			[
				"",
				"AlignTab"
			],
			[
				"syntpy",
				"Set Syntax: Python"
			],
			[
				"mo",
				"File: Move"
			],
			[
				"detro",
				"Origami: Destroy Current Pane"
			],
			[
				"detr",
				"Origami: Destroy Pane on the Right"
			],
			[
				"origami",
				"Origami: Destroy Current Pane"
			],
			[
				"syntaxt",
				"Set Syntax: Tasks"
			],
			[
				"matlab",
				"Set Syntax: MATLAB"
			],
			[
				"syntma",
				"Set Syntax: MATLAB"
			],
			[
				"origaright",
				"Origami: Create Pane on the Right"
			],
			[
				"renam",
				"File: Rename"
			],
			[
				"syntax py",
				"Set Syntax: Python"
			],
			[
				"table",
				"Table Editor: Enable for current syntax"
			],
			[
				"i",
				"MarkdownTOC:Insert TOC"
			],
			[
				"orid",
				"Origami: Destroy Current Pane"
			],
			[
				"extr",
				"Extract Sublime Package: Extract open Package File"
			],
			[
				"update",
				"MarkdownTOC:Update TOC"
			],
			[
				"mar",
				"MarkdownTOC:Insert TOC"
			],
			[
				"install",
				"Package Control: Install Package"
			]
		],
		"width": 540.0
	},
	"console":
	{
		"height": 0.0,
		"history":
		[
		]
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"expanded_folders":
	[
		"/Users/tiepvu/PROJECTS/02_LRSDL/LRSDL_paper",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io",
		"/Users/tiepvu/PROJECTS/ebookFundaML"
	],
	"file_history":
	[
		"/Users/tiepvu/Dropbox/Deep Image Recognition slides/slashbox.sty",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/SCCQ_mu_recluster.py",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/test_labelme3.py",
		"/Users/tiepvu/.zshrc",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/cython/mycython.pyx",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/SCCQ/test_labelme.py",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/SCCQ/mycython.pyx",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/SCCQ/README.md",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/SCCQ/utils.py",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_posts/2017-06-15-pca.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/07_DimemsionalityReduction/27_pca.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/_posts/2017-06-15-pca.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/06_RecommendationSystems/25_matrixfactorizationRS.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/_posts/2017-05-31-matrixfactorization.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/figure_template.tex",
		"/Users/tiepvu/Library/Application Support/Sublime Text 3/Packages/User/fig_side.sublime-snippet",
		"/Users/tiepvu/Library/Application Support/Sublime Text 3/Packages/User/fig_threesubs.sublime-snippet",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/06_RecommendationSystems/24_neighborhoodRS.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/test.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/06_RecommendationSystems/23_contentbasedRS.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/_posts/2017-05-17-contentbasedrecommendersys.md",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/SCCQ_clean2.py",
		"/Users/tiepvu/PROJECTS/ebookFundaML/_posts/2017-04-13-softmarginsvm.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/09_SupportVectorMachines/20_softmaginsvm.tex",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/assets/latex/18_duality.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/chapters/08_ConvexOptimization/16_convexity.aux",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/assets/latex/16_convexity.aux",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/09_SupportVectorMachines/19_svm.tex",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/pytorch_mnist.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/pytorch_sdcn_mlp_un.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/keras_mnist_cnn.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/keras_sdcn_cnn.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/utils.py",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/stat_counter",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_layouts/default.html",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/index.md",
		"/Users/tiepvu/Dropbox/11_iPAL/web_thv102/index.html",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/SDCN2.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/SDCN3.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/data_dem.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/keras_sdcn_mlp.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/SDCN.py",
		"/Users/tiepvu/PROJECTS/05_SRJTT/super_res/src/SRCNN_ver8_Tiep.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/SDCN_2d.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/SDCN_2d_1hid.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/mnist_deep.py",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/test_mnist.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/gan_ex_pytorch2.py",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_posts/2017-07-10-lifesofar.md",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_posts/2017-07-09-prob.md",
		"/Users/tiepvu/.yagmail",
		"/Users/tiepvu/Dropbox/11_iPAL/web_thv102/CV_latex/CV_170907.tex",
		"/Users/tiepvu/PROJECTS/interactive-front-end/app/partials/registration.html",
		"/Users/tiepvu/PROJECTS/interactive-front-end/app/partials/courses.html",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/assets/latex/new_logo_lap.tex",
		"/Users/tiepvu/PROJECTS/CodingInterview/coding_interview.py",
		"/Users/tiepvu/PROJECTS/CodingInterview/LCS.py",
		"/Users/tiepvu/PROJECTS/CodingInterview/Review.md",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/a.txt",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/buymeacoffee.md",
		"/Users/tiepvu/Downloads/BLAS-3.7.1/Makefile",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_layouts/post.html",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_includes/sidebar.html",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/assets/latex/ebook_logo.tex",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_includes/topbar.html",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/.ipynb_checkpoints/TestLabelMe-checkpoint.ipynb",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/SCCQ_0817.py",
		"/Users/tiepvu/PROJECTS/ebookFundaML/python_course.md",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/cifar10_tutorial.py",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/NeuralNets/test.py",
		"/Users/tiepvu/Dropbox/14_TodoNotes/pytorch.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/1.5. Inner product.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/1.4. Tinh toan voi vector.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/1.3. DataType.md",
		"/Users/tiepvu/Downloads/Keras-MNIST-GAN-master/mnist_gan.py",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/README.md",
		"/Users/tiepvu/Desktop/[NIPS 2017: Non-targeted Adversarial Attack]",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/results.md",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_posts/2017-07-15-mlemap.md",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_includes/head.html",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_includes/stat_counter.html",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/.gitignore",
		"/Users/tiepvu/PROJECTS/04_TensorSparsity/ARL_2017/.gitignore",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_posts/2017-04-09-svm.md",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_posts/2017-02-11-binaryclassifiers.markdown",
		"/Users/tiepvu/tmp.py",
		"/Users/tiepvu/.bash_profile",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_posts/2017-08-31-evaluation.md",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/kmcuda-develop/src/test.py",
		"/usr/local/texlive/2016/texmf-dist/tex/generic/babel/babel.sty",
		"/Users/tiepvu/PROJECTS/ebookFundaML/_posts/2017-01-12-gradientdescent.md",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_drafts/probabilisticLinearRegression.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/01_Overview/11_featureengineering.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/test.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/pgfs/logofundaml.tex",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/assets/latex/logo_170718.tex",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/assets/latex/logo.tex",
		"/Users/tiepvu/Library/Application Support/Sublime Text 3/Packages/User/myalg.sublime-snippet",
		"/Users/tiepvu/PROJECTS/ebookFundaML/book_ML.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/01_Overview/02_categories.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/myenv.tex",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/test_nuswide.py",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/08_ConvexOptimization/16_convexity.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/08_ConvexOptimization/17_convexopt.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/08_ConvexOptimization/18_duality.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/input_markdown.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/09_SupportVectorMachines/21_kernelsvm.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/09_SupportVectorMachines/22_multiclasssvm.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/book_ML.fdb_latexmk",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/07_DimemsionalityReduction/26_svd.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/07_DimemsionalityReduction/28_pca2.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/07_DimemsionalityReduction/29_lda.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/05_NeuralNetworks/09_pla.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/05_NeuralNetworks/10_logisticregression.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/_posts/2017-01-27-logisticregression.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/move2trash.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/05_NeuralNetworks/12_binaryclassifiers.tex",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_posts/2017-02-17-softmax.markdown",
		"/Users/tiepvu/PROJECTS/ebookFundaML/_posts/2017-02-24-mlp.md",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/05_NeuralNetworks/13_softmax.tex",
		"/Users/tiepvu/PROJECTS/tiepvupsu.github.io/_posts/2017-02-24-mlp.markdown",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/05_NeuralNetworks/14_mlp.tex",
		"/Users/tiepvu/PROJECTS/ebookFundaML/_posts/2017-01-16-gradientdescent2.md",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/test_labelme2.py",
		"/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/sparse/coo.py",
		"/Users/tiepvu/Desktop/proposal",
		"/Users/tiepvu/PROJECTS/06_Hashing/src/AllCQ/SCCQ_clean.py",
		"/Users/tiepvu/PROJECTS/ebookFundaML/Chapters/04_GradientDescent/7_gradientdescent.tex"
	],
	"find":
	{
		"height": 36.0
	},
	"find_in_files":
	{
		"height": 93.0,
		"where_history":
		[
		]
	},
	"find_state":
	{
		"case_sensitive": true,
		"find_history":
		[
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": false,
		"replace_history":
		[
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"folders":
	[
		{
			"path": "/Users/tiepvu/PROJECTS/02_LRSDL/LRSDL_paper"
		},
		{
			"path": "/Users/tiepvu/PROJECTS/tiepvupsu.github.io"
		},
		{
			"path": "/Users/tiepvu/PROJECTS/ebookFundaML"
		}
	],
	"groups":
	[
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "/Users/tiepvu/PROJECTS/02_LRSDL/LRSDL_paper/GroupMeeting_visitor_170913.tex",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 83131,
						"regions":
						{
						},
						"selection":
						[
							[
								24138,
								24138
							]
						],
						"settings":
						{
							"bracket_highlighter.busy": false,
							"bracket_highlighter.locations":
							{
								"close":
								{
									"1":
									[
										24138,
										24139
									]
								},
								"icon":
								{
									"1":
									[
										"Packages/BracketHighlighter/icons/curly_bracket.png",
										"brackethighlighter.default"
									]
								},
								"open":
								{
									"1":
									[
										24137,
										24138
									]
								},
								"unmatched":
								{
								}
							},
							"bracket_highlighter.regions":
							[
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content"
							],
							"syntax": "Packages/LaTeXing/support/LaTeX Beamer.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 11368.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 27.0
	},
	"input":
	{
		"height": 35.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.exec":
	{
		"height": 423.0
	},
	"output.find_results":
	{
		"height": 0.0
	},
	"output.jotter":
	{
		"height": 124.0
	},
	"output.latextools":
	{
		"height": 287.0
	},
	"output.markdown":
	{
		"height": 100.0
	},
	"output.unsaved_changes":
	{
		"height": 100.0
	},
	"pinned_build_system": "",
	"project": "",
	"replace":
	{
		"height": 50.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"codi",
				"CodingInterview/coding_interview.py"
			],
			[
				"coding",
				"CodingInterview/coding_interview.py"
			],
			[
				"revi",
				"CodingInterview/Review.md"
			],
			[
				"prob.",
				"tiepvupsu.github.io/_posts/2017-07-09-prob.md"
			],
			[
				"",
				"CodingInterview/coding_interview.py"
			],
			[
				"codmd",
				"CodingInterview/Review.md"
			],
			[
				"matrix",
				"CodingInterview/matrixchainmult.py"
			],
			[
				"upc",
				"AllCQ/UCCQ_sepCs.py"
			],
			[
				"reclu",
				"AllCQ/SCCQ_mu_recluster.py"
			],
			[
				"utils",
				"AllCQ/utils.py"
			],
			[
				"sccq_clean",
				"~/PROJECTS/06_Hashing/src/AllCQ/SCCQ_clean.py"
			],
			[
				"solb",
				"AllCQ/solveB_test.py"
			],
			[
				"mycy",
				"AllCQ/cython/mycython.pyx"
			],
			[
				"util",
				"AllCQ/utils.py"
			],
			[
				"solvb",
				"AllCQ/solveB_test.py"
			],
			[
				"myc",
				"AllCQ/cython/mycython.pyx"
			],
			[
				"cdi",
				"AllCQ/cdist_test.py"
			],
			[
				"sccqcl",
				"AllCQ/SCCQ_clean.py"
			],
			[
				"solvbte",
				"AllCQ/solveB_test.py"
			],
			[
				"testlabel2",
				"AllCQ/test_labelme2.py"
			],
			[
				"testmni",
				"AllCQ/test_mnist.py"
			],
			[
				"boo",
				"ebookFundaML/book_ML.tex"
			],
			[
				"test.",
				"ebookFundaML/test.tex"
			],
			[
				"test.tex",
				"ebookFundaML/test.tex"
			],
			[
				"new_logo9te",
				"tiepvupsu.github.io/assets/latex/new_logo9.tex"
			],
			[
				"logo",
				"tiepvupsu.github.io/assets/latex/logo.tex"
			],
			[
				"myen",
				"ebookFundaML/myenv.tex"
			],
			[
				"boomlte",
				"ebookFundaML/book_ML.tex"
			],
			[
				"sccqc",
				"AllCQ/SCCQ_clean.py"
			],
			[
				"mycython",
				"AllCQ/cython/mycython.pyx"
			],
			[
				"mle",
				"tiepvupsu.github.io/_posts/2017-07-15-mlemap.md"
			],
			[
				"sccq",
				"SCCQ/SCCQ.py"
			],
			[
				"sccqcle",
				"AllCQ/SCCQ_clean.py"
			],
			[
				"uti",
				"AllCQ/utils.py"
			],
			[
				"label2",
				"AllCQ/test_labelme2.py"
			],
			[
				"test",
				"AllCQ/test_mnist.py"
			],
			[
				"labelme2",
				"AllCQ/test_labelme2.py"
			],
			[
				"test_la2",
				"AllCQ/test_labelme2.py"
			],
			[
				"my",
				"ebookFundaML/mysvmono.cls"
			],
			[
				"book",
				"ebookFundaML/book_ML.tex"
			],
			[
				"lab2",
				"AllCQ/test_labelme2.py"
			],
			[
				"testlabme2",
				"AllCQ/test_labelme2.py"
			],
			[
				"fit",
				"ebookFundaML/figure_template.tex"
			],
			[
				"sccq_cl",
				"AllCQ/SCCQ_clean.py"
			],
			[
				"out",
				"ebookFundaML/output_latex.tex"
			],
			[
				"md2",
				"ebookFundaML/md2lt.py"
			],
			[
				"kmeans.md",
				"ebookFundaML/_posts/2017-01-01-kmeans.md"
			],
			[
				"3_lin",
				"tiepvupsu.github.io/assets/latex/3_linearregression.tex"
			],
			[
				"outpu",
				"ebookFundaML/output_latex.tex"
			],
			[
				"linear",
				"ebookFundaML/_posts/2016-12-28-linearregression.md"
			],
			[
				"linearre",
				"tiepvupsu.github.io/_drafts/probabilisticLinearRegression.md"
			],
			[
				"7_g",
				"ebookFundaML/Chapters/04_GradientDescent/7_gradientdescent.tex"
			],
			[
				"outp",
				"ebookFundaML/output_latex.tex"
			],
			[
				"gradi2.md",
				"ebookFundaML/_posts/2017-01-16-gradientdescent2.md"
			],
			[
				"gradiendemd",
				"ebookFundaML/_posts/2017-01-12-gradientdescent.md"
			],
			[
				"mlp.ma",
				"tiepvupsu.github.io/_posts/2017-02-24-mlp.markdown"
			],
			[
				"mlp.md",
				"ebookFundaML/_posts/2017-02-24-mlp.md"
			],
			[
				"output",
				"ebookFundaML/output_latex.tex"
			],
			[
				"sofmax.md",
				"tiepvupsu.github.io/_posts/2017-02-17-softmax.markdown"
			],
			[
				"10_",
				"ebookFundaML/Chapters/05_NeuralNetworks/10_logisticregression.tex"
			],
			[
				"bo",
				"ebookFundaML/book_ML.tex"
			],
			[
				"logismd",
				"ebookFundaML/_posts/2017-01-27-logisticregression.md"
			],
			[
				"m",
				"AllCQ/cython/mycython.pyx"
			],
			[
				"eboo",
				"tiepvupsu.github.io/ebook.md"
			],
			[
				"sccq.",
				"SCCQ/SCCQ.py"
			],
			[
				"16_contex",
				"ebookFundaML/Chapters/08_ConvexOptimization/16_convexity.tex"
			],
			[
				"16_con",
				"ebookFundaML/Chapters/08_ConvexOptimization/16_convexity.aux"
			],
			[
				"conveximd",
				"tiepvupsu.github.io/_posts/2017-03-12-convexity.md"
			],
			[
				"labelm",
				"AllCQ/test_labelme2.py"
			],
			[
				"sccq.py",
				"SCCQ/SCCQ.py"
			],
			[
				"sccqclea",
				"AllCQ/SCCQ_clean.py"
			],
			[
				"sccq.p",
				"AllCQ/SCCQ_clean.py"
			],
			[
				"mycytho",
				"AllCQ/cython/mycython.pyx"
			],
			[
				"ebook",
				"tiepvupsu.github.io/ebook.md"
			],
			[
				"testl2",
				"AllCQ/test_labelme2.py"
			],
			[
				"labelme",
				"SCCQ/test_labelme.py"
			],
			[
				"sccq.y",
				"SCCQ/SCCQ.py"
			],
			[
				"mycyt",
				"SCCQ/mycython.pyx"
			],
			[
				"testlabe",
				"SCCQ/test_labelme.py"
			],
			[
				"giti",
				"tiepvupsu.github.io/.gitignore"
			],
			[
				"setu",
				"AllCQ/cython/setup.py"
			],
			[
				"eval",
				"AllCQ/eval.py"
			],
			[
				"model",
				"AllCQ/model.py"
			],
			[
				"gen",
				"ensemble-adv-training-master/gen.py"
			],
			[
				"gen.",
				"ensemble-adv-training-master/gen.py"
			],
			[
				"simp",
				"ensemble-adv-training-master/simple_eval.py"
			],
			[
				"stat",
				"tiepvupsu.github.io/stat_counter"
			],
			[
				"svm.md",
				"tiepvupsu.github.io/_posts/2017-04-09-svm.md"
			],
			[
				"nbc.md",
				"tiepvupsu.github.io/_posts/2017-08-08-nbc.md"
			],
			[
				"te",
				"AllCQ/test_labelme2.py"
			],
			[
				"mypy",
				"AllCQ/cython/mycython.pyx"
			],
			[
				"setup",
				"AllCQ/cython/setup.py"
			],
			[
				"cython",
				"AllCQ/cython/mycython.pyx"
			],
			[
				"27_",
				"ebookFundaML/Chapters/07_DimemsionalityReduction/27_pca.tex"
			],
			[
				"pca.md",
				"tiepvupsu.github.io/_posts/2017-06-15-pca.md"
			],
			[
				"svd.md",
				"tiepvupsu.github.io/_posts/2017-06-07-svd.md"
			],
			[
				"matrifactorization.md",
				"ebookFundaML/_posts/2017-05-31-matrixfactorization.md"
			],
			[
				"figte",
				"ebookFundaML/figure_template.tex"
			],
			[
				"fite",
				"ebookFundaML/figure_template.tex"
			],
			[
				"23_conten",
				"ebookFundaML/Chapters/06_RecommendationSystems/23_contentbasedRS.tex"
			],
			[
				"contentex",
				"tiepvupsu.github.io/assets/23_contentbasedrecommendersys/latex/contentbased.tex"
			],
			[
				"bootex",
				"ebookFundaML/book_ML.tex"
			],
			[
				"labe2",
				"AllCQ/test_labelme2.py"
			],
			[
				"booml.te",
				"ebookFundaML/book_ML.tex"
			],
			[
				"booml",
				"ebookFundaML/book_ML.fdb_latexmk"
			],
			[
				"ou",
				"ebookFundaML/output_latex.tex"
			],
			[
				"sccqre",
				"AllCQ/SCCQ_mu_recluster.py"
			],
			[
				"lab",
				"AllCQ/test_labelme2.py"
			],
			[
				"23_",
				"ebookFundaML/Chapters/06_RecommendationSystems/23_contentbasedRS.tex"
			],
			[
				"labelm2",
				"AllCQ/test_labelme2.py"
			],
			[
				"figu",
				"ebookFundaML/figure_template.tex"
			],
			[
				"figure",
				"ebookFundaML/figure_template.tex"
			],
			[
				"md",
				"04_TensorSparsity/NeuralNets/mnist_deep.py"
			],
			[
				"fi",
				"ebookFundaML/figure_template.tex"
			],
			[
				"figurete",
				"ebookFundaML/figure_template.tex"
			],
			[
				"bookmlte",
				"ebookFundaML/book_ML.tex"
			],
			[
				"test_labe",
				"AllCQ/test_labelme2.py"
			],
			[
				"test_la",
				"AllCQ/test_labelme.py"
			],
			[
				"binary.md",
				"tiepvupsu.github.io/_posts/2017-02-11-binaryclassifiers.markdown"
			],
			[
				"sccqu",
				"AllCQ/SCCQ_mu.py"
			],
			[
				"sccq_mu",
				"AllCQ/SCCQ_mu.py"
			],
			[
				"head",
				"tiepvupsu.github.io/_includes/head.html"
			],
			[
				"statc",
				"tiepvupsu.github.io/_includes/stat_counter.html"
			],
			[
				".gitignore",
				"tiepvupsu.github.io/.gitignore"
			],
			[
				"gitig",
				"ARL_2017/.gitignore"
			],
			[
				"mlem",
				"tiepvupsu.github.io/_posts/2017-07-15-mlemap.md"
			],
			[
				"res",
				"AllCQ/results.md"
			],
			[
				"sccqmu",
				"AllCQ/SCCQ_mu.py"
			]
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 500.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 380.0
	},
	"select_symbol":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": false,
	"show_open_files": false,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 226.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
